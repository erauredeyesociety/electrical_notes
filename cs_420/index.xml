<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Electrical Notes â€“ Cs_420s</title><link>https://erauredeyesociety.github.io/electrical_notes/cs_420/</link><description>Recent content in Cs_420s on Electrical Notes</description><generator>Hugo -- gohugo.io</generator><language>en</language><atom:link href="https://erauredeyesociety.github.io/electrical_notes/cs_420/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://erauredeyesociety.github.io/electrical_notes/cs_420/ass1_ass2_topics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://erauredeyesociety.github.io/electrical_notes/cs_420/ass1_ass2_topics/</guid><description>
&lt;h1&gt;Operating Systems Theory - Complete Study Guide&lt;/h1&gt;&lt;p&gt;&lt;em&gt;Comprehensive coverage for Assignments 1 &amp;amp; 2&lt;/em&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;1. Functions of an Operating System&lt;span class="hx:absolute hx:-mt-20" id="1-functions-of-an-operating-system"&gt;&lt;/span&gt;
&lt;a href="#1-functions-of-an-operating-system" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;What is an Operating System?&lt;span class="hx:absolute hx:-mt-20" id="what-is-an-operating-system"&gt;&lt;/span&gt;
&lt;a href="#what-is-an-operating-system" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;An operating system is an intermediary program that sits between users and computer hardware, creating an environment where other programs can do useful work. Like a government, it doesn&amp;rsquo;t do productive work itself but provides the framework for others to operate efficiently.&lt;/p&gt;
&lt;h3&gt;Primary Goals&lt;span class="hx:absolute hx:-mt-20" id="primary-goals"&gt;&lt;/span&gt;
&lt;a href="#primary-goals" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Execute user programs&lt;/strong&gt; - Make solving user problems easier&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Convenience&lt;/strong&gt; - Make the computer system easy to use&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Efficiency&lt;/strong&gt; - Use hardware resources optimally&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reliability &amp;amp; Safety&lt;/strong&gt; - Prevent errors and improper computer use&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Core Roles&lt;span class="hx:absolute hx:-mt-20" id="core-roles"&gt;&lt;/span&gt;
&lt;a href="#core-roles" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Resource Allocator&lt;/strong&gt;
The OS manages all system resources (CPU time, memory space, file storage, I/O devices) and mediates between conflicting requests to ensure efficient and fair usage.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Control Program&lt;/strong&gt;
Controls program execution to prevent errors and improper computer use, maintaining system integrity and security.&lt;/p&gt;
&lt;h3&gt;Key Operating System Services&lt;span class="hx:absolute hx:-mt-20" id="key-operating-system-services"&gt;&lt;/span&gt;
&lt;a href="#key-operating-system-services" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Service&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;User Interface&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Provides CLI, GUI, or Batch interfaces for user interaction&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Program Execution&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Loads programs into memory, executes them, handles termination (normal or error)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;I/O Operations&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Manages I/O device operations, file access, and device communication&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;File-System Manipulation&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Enables reading, writing, creating, deleting files; managing directories and permissions&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Communications (IPC)&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Allows processes to exchange information via shared memory or message passing&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Error Detection&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Constantly monitors for hardware/software errors and takes corrective action&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Resource Allocation&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Distributes CPU cycles, memory, storage, and I/O among concurrent processes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Protection &amp;amp; Security&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Controls resource access and defends against unauthorized external access&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;System Components&lt;span class="hx:absolute hx:-mt-20" id="system-components"&gt;&lt;/span&gt;
&lt;a href="#system-components" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Four Components of a Computer System:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Hardware&lt;/strong&gt; - CPU, memory, I/O devices (provides basic computing resources)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Operating System&lt;/strong&gt; - Controls and coordinates hardware use among applications&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Application Programs&lt;/strong&gt; - Define how system resources solve user problems&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Users&lt;/strong&gt; - People, machines, or other computers using the system&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;What runs all the time?&lt;/strong&gt; The &lt;strong&gt;kernel&lt;/strong&gt; is the one program running continuously on the computer. Everything else is either a system program (shipped with OS) or an application program.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;2. Interrupt Handling&lt;span class="hx:absolute hx:-mt-20" id="2-interrupt-handling"&gt;&lt;/span&gt;
&lt;a href="#2-interrupt-handling" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;What are Interrupts?&lt;span class="hx:absolute hx:-mt-20" id="what-are-interrupts"&gt;&lt;/span&gt;
&lt;a href="#what-are-interrupts" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;The operating system is &lt;strong&gt;interrupt-driven&lt;/strong&gt; - it responds to events rather than running continuously. Interrupts signal that something requires the OS&amp;rsquo;s attention.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Types of Interrupts:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hardware Interrupt&lt;/strong&gt; - Generated by hardware devices (e.g., I/O device completing an operation)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Software Interrupt (Trap/Exception)&lt;/strong&gt; - Caused by software errors (division by zero) or user requests (system calls)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Interrupt Handling Sequence&lt;span class="hx:absolute hx:-mt-20" id="interrupt-handling-sequence"&gt;&lt;/span&gt;
&lt;a href="#interrupt-handling-sequence" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Interrupt Trigger&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;An I/O device controller signals completion by causing a hardware interrupt&lt;/li&gt;
&lt;li&gt;OR a trap/exception occurs from an error or system call&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Control Transfer&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU stops current execution&lt;/li&gt;
&lt;li&gt;Control transfers to the &lt;strong&gt;interrupt service routine&lt;/strong&gt; (ISR)&lt;/li&gt;
&lt;li&gt;Transfer uses the &lt;strong&gt;interrupt vector&lt;/strong&gt; - a table containing memory addresses of all service routines&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;State Preservation&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The address of the interrupted instruction is saved&lt;/li&gt;
&lt;li&gt;CPU registers and process state are saved to allow resumption later&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Kernel Mode Entry&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If the interrupt is a system call requesting OS services, the &lt;strong&gt;mode bit&lt;/strong&gt; changes to &lt;strong&gt;kernel mode&lt;/strong&gt; (supervisor mode)&lt;/li&gt;
&lt;li&gt;This allows execution of privileged instructions that user programs cannot execute&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Service Routine Execution&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The CPU executes the appropriate service routine based on the interrupt type&lt;/li&gt;
&lt;li&gt;The routine handles the event (service I/O, respond to system call, handle error)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Return to User Mode&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;After handling the interrupt, the mode bit changes back to &lt;strong&gt;user mode&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Execution resumes from the saved instruction address&lt;/li&gt;
&lt;li&gt;The system returns control to the interrupted process&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;CPU Mode Switching&lt;span class="hx:absolute hx:-mt-20" id="cpu-mode-switching"&gt;&lt;/span&gt;
&lt;a href="#cpu-mode-switching" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;User Mode&lt;/strong&gt; - Limited instruction set; cannot execute privileged operations
&lt;strong&gt;Kernel Mode&lt;/strong&gt; - Full access to all hardware and memory; can execute any instruction&lt;/p&gt;
&lt;p&gt;The mode bit prevents user programs from interfering with OS operations or other users&amp;rsquo; programs.&lt;/p&gt;
&lt;h3&gt;Timer Interrupts&lt;span class="hx:absolute hx:-mt-20" id="timer-interrupts"&gt;&lt;/span&gt;
&lt;a href="#timer-interrupts" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;A &lt;strong&gt;timer&lt;/strong&gt; (set by privileged instruction) can interrupt the computer after a specified period, ensuring the OS regains control periodically. This prevents any single process from monopolizing the CPU and enables time-sharing systems.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;3. Bootstrapping and System Calls&lt;span class="hx:absolute hx:-mt-20" id="3-bootstrapping-and-system-calls"&gt;&lt;/span&gt;
&lt;a href="#3-bootstrapping-and-system-calls" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Bootstrap Process&lt;span class="hx:absolute hx:-mt-20" id="bootstrap-process"&gt;&lt;/span&gt;
&lt;a href="#bootstrap-process" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;What is a Bootstrap Program?&lt;/strong&gt;
A small piece of code that initializes the system when the computer is powered on or rebooted. It locates and loads the operating system kernel into memory.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Where is it stored?&lt;/strong&gt;
In ROM (Read-Only Memory), EPROM (Erasable Programmable ROM), or firmware. This non-volatile storage ensures the bootstrap code is always available at startup.&lt;/p&gt;
&lt;h3&gt;System Calls&lt;span class="hx:absolute hx:-mt-20" id="system-calls"&gt;&lt;/span&gt;
&lt;a href="#system-calls" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;What are System Calls?&lt;/strong&gt;
System calls provide the &lt;strong&gt;interface to OS services&lt;/strong&gt; - they are the mechanism by which user programs request services from the operating system kernel.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;API, System-Call Interface, and OS Relationship:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;API (Application Programming Interface)&lt;/strong&gt; - High-level functions programmers use (e.g., &lt;code&gt;open()&lt;/code&gt;, &lt;code&gt;read()&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;System-Call Interface&lt;/strong&gt; - Intercepts API calls and invokes appropriate system calls in the OS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Operating System&lt;/strong&gt; - Executes the requested service in kernel mode&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Three Methods to Pass Parameters:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Registers&lt;/strong&gt; - Pass parameters directly in CPU registers (simplest, but limited)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memory Block/Table&lt;/strong&gt; - Store parameters in memory, pass address in register (used when many parameters)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stack&lt;/strong&gt; - Push parameters onto the program stack, OS pops them off (flexible)&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;4. Process Management&lt;span class="hx:absolute hx:-mt-20" id="4-process-management"&gt;&lt;/span&gt;
&lt;a href="#4-process-management" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Process Fundamentals&lt;span class="hx:absolute hx:-mt-20" id="process-fundamentals"&gt;&lt;/span&gt;
&lt;a href="#process-fundamentals" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;What is a Process?&lt;/strong&gt;
A &lt;strong&gt;process&lt;/strong&gt; is a program in execution - the active unit of work in a system. A program is merely a passive entity (executable file), while a process is active with a program counter and resources.&lt;/p&gt;
&lt;h3&gt;Process Memory Layout&lt;span class="hx:absolute hx:-mt-20" id="process-memory-layout"&gt;&lt;/span&gt;
&lt;a href="#process-memory-layout" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;A process&amp;rsquo;s memory is divided into sections:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Text Section&lt;/strong&gt; - Executable code&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Section&lt;/strong&gt; - Global variables&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Heap Section&lt;/strong&gt; - Dynamically allocated memory during runtime (grows upward)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stack Section&lt;/strong&gt; - Temporary data (function parameters, return addresses, local variables)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Question: What area contains dynamically allocated data?&lt;/strong&gt;
The &lt;strong&gt;heap section&lt;/strong&gt; contains data allocated during runtime via functions like &lt;code&gt;malloc()&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Process States&lt;span class="hx:absolute hx:-mt-20" id="process-states"&gt;&lt;/span&gt;
&lt;a href="#process-states" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;A process changes state as it executes:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;State&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;New&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Process is being created&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Running&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Instructions are being executed on CPU&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Waiting&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Process is waiting for an event (I/O completion, signal)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Ready&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Process is waiting to be assigned to a CPU&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Terminated&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Process has finished execution&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;State Transitions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Running â†’ Waiting: Process makes I/O request&lt;/li&gt;
&lt;li&gt;Running â†’ Ready: Interrupt occurs (time slice expires)&lt;/li&gt;
&lt;li&gt;Waiting â†’ Ready: I/O or event completes&lt;/li&gt;
&lt;li&gt;Ready â†’ Running: Scheduler selects this process&lt;/li&gt;
&lt;li&gt;Running â†’ Terminated: Process completes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;When is a process forced off the CPU?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I/O request (voluntary)&lt;/li&gt;
&lt;li&gt;Time slice expiration (involuntary preemption)&lt;/li&gt;
&lt;li&gt;Interrupt occurrence (involuntary)&lt;/li&gt;
&lt;li&gt;Calling &lt;code&gt;fork()&lt;/code&gt; may trigger scheduling (depends on implementation)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Process Control Block (PCB)&lt;span class="hx:absolute hx:-mt-20" id="process-control-block-pcb"&gt;&lt;/span&gt;
&lt;a href="#process-control-block-pcb" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;The &lt;strong&gt;PCB&lt;/strong&gt; is the data structure containing all information associated with a process:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Process state&lt;/li&gt;
&lt;li&gt;Program counter (next instruction address)&lt;/li&gt;
&lt;li&gt;CPU registers (contents of all process-centric registers)&lt;/li&gt;
&lt;li&gt;CPU scheduling information (priority, queue pointers)&lt;/li&gt;
&lt;li&gt;Memory management information (page tables, segment tables)&lt;/li&gt;
&lt;li&gt;Accounting information (CPU used, time limits)&lt;/li&gt;
&lt;li&gt;I/O status information (allocated devices, open files)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Process Creation&lt;span class="hx:absolute hx:-mt-20" id="process-creation"&gt;&lt;/span&gt;
&lt;a href="#process-creation" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Parent-Child Relationships:&lt;/strong&gt;
Parent processes create children processes, forming a &lt;strong&gt;process tree&lt;/strong&gt;. The root is the init process (PID 1 on UNIX systems).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;UNIX Process Creation:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;fork()&lt;/code&gt; - System call that creates a new process (child) by duplicating the parent
&lt;ul&gt;
&lt;li&gt;Child receives a copy of the parent&amp;rsquo;s address space&lt;/li&gt;
&lt;li&gt;Returns 0 to child, child&amp;rsquo;s PID to parent&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;exec()&lt;/code&gt; - Replaces the child process&amp;rsquo;s memory space with a new program
&lt;ul&gt;
&lt;li&gt;Overlays the current process image with a new program&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;What happens if you call &lt;code&gt;exec()&lt;/code&gt; before &lt;code&gt;fork()&lt;/code&gt;?&lt;/strong&gt;
If you call &lt;code&gt;exec()&lt;/code&gt; before &lt;code&gt;fork()&lt;/code&gt;, the current process is replaced by the new program, and the &lt;code&gt;fork()&lt;/code&gt; call never executes. You cannot create a child process because the code containing &lt;code&gt;fork()&lt;/code&gt; has been overwritten.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why does Google Chrome use multiple processes?&lt;/strong&gt;
Chrome uses separate processes for different tabs and plugins to provide isolation - if one tab crashes or is compromised, it doesn&amp;rsquo;t affect other tabs. This improves stability, security, and allows better resource management.&lt;/p&gt;
&lt;h3&gt;Interprocess Communication (IPC)&lt;span class="hx:absolute hx:-mt-20" id="interprocess-communication-ipc"&gt;&lt;/span&gt;
&lt;a href="#interprocess-communication-ipc" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Cooperating processes need mechanisms to share information. Two fundamental models:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Shared Memory&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Processes share a region of memory&lt;/li&gt;
&lt;li&gt;Fast (no kernel intervention after setup)&lt;/li&gt;
&lt;li&gt;Requires synchronization by processes themselves&lt;/li&gt;
&lt;li&gt;Used in Assignment 1 for bounded buffer&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. Message Passing&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Processes communicate by sending/receiving messages through the kernel&lt;/li&gt;
&lt;li&gt;Slower (kernel mediation for each message)&lt;/li&gt;
&lt;li&gt;Easier to implement, especially for distributed systems&lt;/li&gt;
&lt;li&gt;No synchronization conflicts&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;5. Thread Management&lt;span class="hx:absolute hx:-mt-20" id="5-thread-management"&gt;&lt;/span&gt;
&lt;a href="#5-thread-management" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Thread Fundamentals&lt;span class="hx:absolute hx:-mt-20" id="thread-fundamentals"&gt;&lt;/span&gt;
&lt;a href="#thread-fundamentals" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;What is a Thread?&lt;/strong&gt;
A &lt;strong&gt;thread&lt;/strong&gt; is a fundamental unit of CPU utilization, consisting of a thread ID, program counter, register set, and stack. Multiple threads within the same process share code, data, and files.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Single-threaded vs. Multithreaded Process:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Single-threaded: One program counter, one sequence of execution&lt;/li&gt;
&lt;li&gt;Multithreaded: Multiple program counters, multiple concurrent execution sequences&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Why shouldn&amp;rsquo;t a web server be single-threaded?&lt;/strong&gt;
A single-threaded web server can only handle one request at a time. While waiting for disk I/O or network operations for one client, it cannot service other clients, resulting in terrible performance and responsiveness.&lt;/p&gt;
&lt;h3&gt;Items Shared Among Threads&lt;span class="hx:absolute hx:-mt-20" id="items-shared-among-threads"&gt;&lt;/span&gt;
&lt;a href="#items-shared-among-threads" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Threads of the same process share:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Code section&lt;/strong&gt; (text)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data section&lt;/strong&gt; (global variables)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Open files&lt;/strong&gt; and other OS resources&lt;/li&gt;
&lt;li&gt;Heap memory&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each thread has its own:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Program counter&lt;/li&gt;
&lt;li&gt;Register set&lt;/li&gt;
&lt;li&gt;Stack (for local variables and function calls)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Four Major Benefits of Multithreading&lt;span class="hx:absolute hx:-mt-20" id="four-major-benefits-of-multithreading"&gt;&lt;/span&gt;
&lt;a href="#four-major-benefits-of-multithreading" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. Responsiveness&lt;/strong&gt;
Allows a program to continue running even if part of it is blocked. Critical for user interfaces - one thread can handle user input while another performs lengthy computation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. Resource Sharing&lt;/strong&gt;
Threads automatically share the memory and resources of their parent process. This is simpler and more efficient than implementing shared memory or message passing between separate processes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. Economy&lt;/strong&gt;
Thread creation and management is &amp;ldquo;lightweight&amp;rdquo; compared to &amp;ldquo;heavy-weight&amp;rdquo; process creation. Creating a thread is typically 10-100 times faster than creating a process. Context switching between threads of the same process is also much cheaper than process context switching.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. Scalability&lt;/strong&gt;
A multithreaded process can take advantage of multiprocessor architectures, with threads running in parallel on different cores. This enables true parallelism on multicore systems.&lt;/p&gt;
&lt;h3&gt;Multithreading Models&lt;span class="hx:absolute hx:-mt-20" id="multithreading-models"&gt;&lt;/span&gt;
&lt;a href="#multithreading-models" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Threads exist at two levels: &lt;strong&gt;user threads&lt;/strong&gt; (managed by user-level libraries) and &lt;strong&gt;kernel threads&lt;/strong&gt; (managed by the OS).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;Mapping&lt;/th&gt;
&lt;th&gt;Assessment&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Many-to-One&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Many user threads â†’ 1 kernel thread&lt;/td&gt;
&lt;td&gt;Poor concurrency: if one thread blocks, all block. Rarely used today.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;One-to-One&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;1 user thread â†’ 1 kernel thread&lt;/td&gt;
&lt;td&gt;Good concurrency, commonly used (Windows, Linux). Overhead may limit total thread count.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Many-to-Many&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Many user threads â†’ fewer/equal kernel threads&lt;/td&gt;
&lt;td&gt;OS creates optimal number of kernel threads. Flexible but complex.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Common Thread Libraries:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;POSIX Pthreads (UNIX/Linux)&lt;/li&gt;
&lt;li&gt;Windows threads&lt;/li&gt;
&lt;li&gt;Java threads&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Thread Pools&lt;span class="hx:absolute hx:-mt-20" id="thread-pools"&gt;&lt;/span&gt;
&lt;a href="#thread-pools" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;What is a Thread Pool?&lt;/strong&gt;
A set of pre-created threads that wait for work to arrive. Instead of creating a new thread for each task, tasks are submitted to the pool, and an available thread executes them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why use Thread Pools?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Faster service&lt;/strong&gt; - No delay for thread creation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Limited resources&lt;/strong&gt; - Bounds the number of concurrent threads, preventing resource exhaustion&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Separation of concerns&lt;/strong&gt; - Separates task creation from task execution mechanics&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;6. CPU Scheduling&lt;span class="hx:absolute hx:-mt-20" id="6-cpu-scheduling"&gt;&lt;/span&gt;
&lt;a href="#6-cpu-scheduling" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Scheduling Fundamentals&lt;span class="hx:absolute hx:-mt-20" id="scheduling-fundamentals"&gt;&lt;/span&gt;
&lt;a href="#scheduling-fundamentals" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;What is CPU Scheduling?&lt;/strong&gt;
The &lt;strong&gt;short-term scheduler&lt;/strong&gt; (CPU scheduler) selects which process from the ready queue should execute next on the CPU.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dispatcher:&lt;/strong&gt;
The dispatcher is the module that gives control of the CPU to the process selected by the scheduler. It performs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Context switching&lt;/li&gt;
&lt;li&gt;Switching to user mode&lt;/li&gt;
&lt;li&gt;Jumping to the proper location in the user program&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Dispatch latency&lt;/strong&gt; is the time it takes to stop one process and start another.&lt;/p&gt;
&lt;h3&gt;When Does Scheduling Occur?&lt;span class="hx:absolute hx:-mt-20" id="when-does-scheduling-occur"&gt;&lt;/span&gt;
&lt;a href="#when-does-scheduling-occur" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Nonpreemptive (Cooperative) Scheduling:&lt;/strong&gt;
Scheduling decisions occur only when a process:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Switches from running to waiting state (I/O request)&lt;/li&gt;
&lt;li&gt;Terminates&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The process voluntarily relinquishes the CPU.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Preemptive Scheduling:&lt;/strong&gt;
Scheduling decisions also occur when a process:
3. Switches from running to ready (interrupt, time slice expires)
4. Switches from waiting to ready (I/O completes, higher priority process arrives)&lt;/p&gt;
&lt;p&gt;The OS can forcibly remove a process from the CPU.&lt;/p&gt;
&lt;h3&gt;Scheduling Criteria&lt;span class="hx:absolute hx:-mt-20" id="scheduling-criteria"&gt;&lt;/span&gt;
&lt;a href="#scheduling-criteria" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Goals for scheduling algorithm performance:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Criterion&lt;/th&gt;
&lt;th&gt;Goal&lt;/th&gt;
&lt;th&gt;Most Important For&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;CPU Utilization&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Maximize&lt;/td&gt;
&lt;td&gt;General efficiency&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Throughput&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Maximize (processes completed per time unit)&lt;/td&gt;
&lt;td&gt;Batch systems&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Turnaround Time&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Minimize (submission to completion time)&lt;/td&gt;
&lt;td&gt;Batch systems&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Waiting Time&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Minimize (time spent in ready queue)&lt;/td&gt;
&lt;td&gt;All systems&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Response Time&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Minimize (request to first response time)&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Interactive systems&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Which is most important for interactive systems?&lt;/strong&gt;
&lt;strong&gt;Response time&lt;/strong&gt; - users notice delays between requests and responses.&lt;/p&gt;
&lt;h3&gt;Scheduling Algorithms&lt;span class="hx:absolute hx:-mt-20" id="scheduling-algorithms"&gt;&lt;/span&gt;
&lt;a href="#scheduling-algorithms" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;h4&gt;1. First-Come, First-Served (FCFS)&lt;span class="hx:absolute hx:-mt-20" id="1-first-come-first-served-fcfs"&gt;&lt;/span&gt;
&lt;a href="#1-first-come-first-served-fcfs" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
Processes are served in arrival order using a FIFO queue. Nonpreemptive.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Must be nonpreemptive?&lt;/strong&gt; Yes, FCFS is always nonpreemptive.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; Simple to implement&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disadvantage:&lt;/strong&gt; &lt;strong&gt;Convoy effect&lt;/strong&gt; - short processes get stuck behind long processes, causing high average waiting time&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disk scheduling disadvantage:&lt;/strong&gt; Long waits because head position is ignored&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2. Shortest-Job-First (SJF)&lt;span class="hx:absolute hx:-mt-20" id="2-shortest-job-first-sjf"&gt;&lt;/span&gt;
&lt;a href="#2-shortest-job-first-sjf" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
Schedules the process with the shortest next CPU burst. Burst length can be predicted using exponential averaging of past bursts.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; &lt;strong&gt;Optimal&lt;/strong&gt; - gives minimum average waiting time for a given set of processes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disadvantage:&lt;/strong&gt; Difficulty predicting the length of the next CPU burst&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Can cause &lt;strong&gt;starvation&lt;/strong&gt; of longer processes&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;3. Shortest-Remaining-Time-First (SRTF)&lt;span class="hx:absolute hx:-mt-20" id="3-shortest-remaining-time-first-srtf"&gt;&lt;/span&gt;
&lt;a href="#3-shortest-remaining-time-first-srtf" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
Preemptive version of SJF. When a new process arrives with a shorter burst time than the remaining time of the currently running process, the current process is preempted.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Optimal for preemptive scenarios&lt;/li&gt;
&lt;li&gt;High context switch overhead&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;4. Priority Scheduling&lt;span class="hx:absolute hx:-mt-20" id="4-priority-scheduling"&gt;&lt;/span&gt;
&lt;a href="#4-priority-scheduling" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
CPU allocated based on priority number (typically smallest integer = highest priority). Can be preemptive or nonpreemptive.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Preemption Variants:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PR noPREMP (Assignment 2):&lt;/strong&gt; Scheduling only on termination; select highest priority ready process&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PR withPREMP (Assignment 2):&lt;/strong&gt; Also schedule when higher priority process arrives, preempting current process&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; Important tasks get CPU time&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Problem:&lt;/strong&gt; &lt;strong&gt;Starvation&lt;/strong&gt; - low-priority processes may never execute&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Solution:&lt;/strong&gt; &lt;strong&gt;Aging&lt;/strong&gt; - gradually increase the priority of processes waiting a long time&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;What is Starvation?&lt;/strong&gt;
A situation where a process waits indefinitely because other processes continually receive preference.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How does Aging prevent it?&lt;/strong&gt;
By increasing a process&amp;rsquo;s priority as it waits longer, aging eventually makes every waiting process competitive for CPU time.&lt;/p&gt;
&lt;h4&gt;5. Round Robin (RR)&lt;span class="hx:absolute hx:-mt-20" id="5-round-robin-rr"&gt;&lt;/span&gt;
&lt;a href="#5-round-robin-rr" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
Each process gets a small &lt;strong&gt;time quantum&lt;/strong&gt; (typically 10-100 milliseconds). After the quantum expires, the process is preempted and added to the end of the ready queue (circular FIFO).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assignment 2 specifics:&lt;/strong&gt; Processes added to queue in arrival order; if quantum expires, go to end of queue.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; Good response time, fair&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disadvantage:&lt;/strong&gt; High overhead if quantum too small (relative to context switch time)&lt;/li&gt;
&lt;li&gt;If quantum too large, behaves like FCFS&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;6. Multilevel Feedback Queue&lt;span class="hx:absolute hx:-mt-20" id="6-multilevel-feedback-queue"&gt;&lt;/span&gt;
&lt;a href="#6-multilevel-feedback-queue" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
Multiple ready queues with different priorities. Processes can move between queues based on CPU behavior.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Typical Configuration:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;High-priority queues use RR with small quanta (interactive jobs)&lt;/li&gt;
&lt;li&gt;Low-priority queues use RR with large quanta or FCFS (CPU-bound jobs)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; Aging easily implemented; adapts to process behavior&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disadvantage:&lt;/strong&gt; Highly configurable but complex to tune&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Real-Time Scheduling Concepts&lt;span class="hx:absolute hx:-mt-20" id="real-time-scheduling-concepts"&gt;&lt;/span&gt;
&lt;a href="#real-time-scheduling-concepts" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Two Types of Latency:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Interrupt Latency&lt;/strong&gt; - Time from interrupt arrival to service routine start&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dispatch Latency&lt;/strong&gt; - Time to stop current process and start new one&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Both must be minimized for real-time systems to meet deadlines.&lt;/p&gt;
&lt;h3&gt;Concurrency vs. Parallelism&lt;span class="hx:absolute hx:-mt-20" id="concurrency-vs-parallelism"&gt;&lt;/span&gt;
&lt;a href="#concurrency-vs-parallelism" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Concurrency:&lt;/strong&gt;
Multiple tasks making progress, typically by multiplexing CPU time (time-sharing). Possible on a single-processor system.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Parallelism:&lt;/strong&gt;
Multiple tasks executing simultaneously, requires multi-core or multi-processor hardware.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Which term describes multiple tasks making progress on a single processor?&lt;/strong&gt;
&lt;strong&gt;Concurrency&lt;/strong&gt; - tasks interleave execution through time-slicing.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;7. Concurrency and Synchronization&lt;span class="hx:absolute hx:-mt-20" id="7-concurrency-and-synchronization"&gt;&lt;/span&gt;
&lt;a href="#7-concurrency-and-synchronization" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;The Problem: Race Conditions&lt;span class="hx:absolute hx:-mt-20" id="the-problem-race-conditions"&gt;&lt;/span&gt;
&lt;a href="#the-problem-race-conditions" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;What is a Race Condition?&lt;/strong&gt;
Occurs when multiple processes concurrently access and manipulate shared data, and the outcome depends on the particular order of access. This leads to inconsistent or incorrect results.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; Two processes incrementing a shared counter - the final value depends on the timing of their memory reads and writes.&lt;/p&gt;
&lt;h3&gt;Critical Section Problem&lt;span class="hx:absolute hx:-mt-20" id="critical-section-problem"&gt;&lt;/span&gt;
&lt;a href="#critical-section-problem" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Critical Section (CS):&lt;/strong&gt;
A segment of code where a process accesses shared resources that must not be accessed by other processes concurrently.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Three Requirements for a Solution:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Mutual Exclusion&lt;/strong&gt;
If process Pi is executing in its critical section, no other process can execute in their critical sections.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Progress&lt;/strong&gt;
If no process is in the CS and some processes wish to enter, the selection of the next process cannot be postponed indefinitely. Only processes not in their remainder section can participate in the decision.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Bounded Waiting&lt;/strong&gt;
A limit must exist on the number of times other processes can enter their CS after a process requests entry and before that request is granted. Prevents starvation.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Relationship:&lt;/strong&gt; All three are necessary. Mutual exclusion alone could cause deadlock. Progress without bounded waiting could cause starvation. All three together ensure correct, fair synchronization.&lt;/p&gt;
&lt;h3&gt;Synchronization Mechanisms&lt;span class="hx:absolute hx:-mt-20" id="synchronization-mechanisms"&gt;&lt;/span&gt;
&lt;a href="#synchronization-mechanisms" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;h4&gt;1. Mutex Locks&lt;span class="hx:absolute hx:-mt-20" id="1-mutex-locks"&gt;&lt;/span&gt;
&lt;a href="#1-mutex-locks" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
Simplest synchronization tool. A binary lock that protects a critical section.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Operations:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;acquire()&lt;/code&gt; - Obtain the lock before entering CS&lt;/li&gt;
&lt;li&gt;&lt;code&gt;release()&lt;/code&gt; - Release the lock when exiting CS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; Simple concept&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disadvantage:&lt;/strong&gt; Requires &lt;strong&gt;busy waiting&lt;/strong&gt; (spinlock) - process loops waiting for lock, wasting CPU cycles&lt;/li&gt;
&lt;li&gt;Both operations must be &lt;strong&gt;atomic&lt;/strong&gt; (indivisible)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2. Semaphores&lt;span class="hx:absolute hx:-mt-20" id="2-semaphores"&gt;&lt;/span&gt;
&lt;a href="#2-semaphores" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
An integer variable S accessed only through two atomic operations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;wait(S)&lt;/code&gt; or &lt;code&gt;P(S)&lt;/code&gt; - Decrement; wait if value becomes negative&lt;/li&gt;
&lt;li&gt;&lt;code&gt;signal(S)&lt;/code&gt; or &lt;code&gt;V(S)&lt;/code&gt; - Increment; may wake a waiting process&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Types:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Binary Semaphore:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Range: 0 or 1&lt;/li&gt;
&lt;li&gt;Equivalent to a mutex lock&lt;/li&gt;
&lt;li&gt;Used for mutual exclusion&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Counting Semaphore:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Range: unrestricted integer domain&lt;/li&gt;
&lt;li&gt;Can control access to a resource with a finite number of instances&lt;/li&gt;
&lt;li&gt;Initial value = number of available resources&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Can counting semaphores control access to resources with finite instances?&lt;/strong&gt;
&lt;strong&gt;Yes&lt;/strong&gt; - initialize the semaphore to the number of available resources. Each &lt;code&gt;wait()&lt;/code&gt; consumes one resource; each &lt;code&gt;signal()&lt;/code&gt; releases one.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Implementation Without Busy Waiting:&lt;/strong&gt;
Use a &lt;strong&gt;waiting queue&lt;/strong&gt; to store blocked processes. When a process must wait, it&amp;rsquo;s placed in the queue and its state becomes waiting. When &lt;code&gt;signal()&lt;/code&gt; is called, a process from the queue is awakened and moved to the ready queue.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Semaphores vs. Mutex Locks:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Semaphores are more general (counting vs. binary)&lt;/li&gt;
&lt;li&gt;Semaphores can be used for synchronization beyond mutual exclusion&lt;/li&gt;
&lt;li&gt;Mutex is simpler, semantically clearer for mutual exclusion&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;3. Monitors&lt;span class="hx:absolute hx:-mt-20" id="3-monitors"&gt;&lt;/span&gt;
&lt;a href="#3-monitors" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
A high-level abstraction (Abstract Data Type) providing a convenient and effective process synchronization mechanism. Only one process can be active within the monitor at any time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Condition Variables:&lt;/strong&gt;
Used to suspend and resume processes within the monitor:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;x.wait()&lt;/code&gt; - Suspend the calling process&lt;/li&gt;
&lt;li&gt;&lt;code&gt;x.signal()&lt;/code&gt; - Resume one waiting process&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; Easier to ensure correctness than semaphores; mutual exclusion built-in&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disadvantage:&lt;/strong&gt; Not as widely supported; requires language/compiler support&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Standard Concurrency Problems&lt;span class="hx:absolute hx:-mt-20" id="standard-concurrency-problems"&gt;&lt;/span&gt;
&lt;a href="#standard-concurrency-problems" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;h4&gt;Bounded-Buffer (Producer-Consumer)&lt;span class="hx:absolute hx:-mt-20" id="bounded-buffer-producer-consumer"&gt;&lt;/span&gt;
&lt;a href="#bounded-buffer-producer-consumer" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt;
Producer creates items and places them in a bounded buffer. Consumer removes items. Buffer has limited capacity.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution Using Semaphores (Assignment 1 Concept):&lt;/strong&gt;&lt;/p&gt;
&lt;div class="hextra-code-block hx:relative hx:mt-6 hx:first:mt-0 hx:group/code"&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;Semaphores:
- mutex = 1 // Mutual exclusion for buffer access
- empty = n // Count of empty slots
- full = 0 // Count of full slots
Producer:
wait(empty) // Wait if buffer full
wait(mutex) // Enter critical section
[add item to buffer]
signal(mutex) // Exit critical section
signal(full) // Signal item added
Consumer:
wait(full) // Wait if buffer empty
wait(mutex) // Enter critical section
[remove item from buffer]
signal(mutex) // Exit critical section
signal(empty) // Signal slot freed&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class="hextra-code-copy-btn-container hx:opacity-0 hx:transition hx:group-hover/code:opacity-100 hx:flex hx:gap-1 hx:absolute hx:m-[11px] hx:right-0 hx:top-0"&gt;
&lt;button
class="hextra-code-copy-btn hx:group/copybtn hx:cursor-pointer hx:transition-all hx:active:opacity-50 hx:bg-primary-700/5 hx:border hx:border-black/5 hx:text-gray-600 hx:hover:text-gray-900 hx:rounded-md hx:p-1.5 hx:dark:bg-primary-300/10 hx:dark:border-white/10 hx:dark:text-gray-400 hx:dark:hover:text-gray-50"
title="Copy code"
&gt;
&lt;div class="hextra-copy-icon hx:group-[.copied]/copybtn:hidden hx:pointer-events-none hx:h-4 hx:w-4"&gt;&lt;/div&gt;
&lt;div class="hextra-success-icon hx:hidden hx:group-[.copied]/copybtn:block hx:pointer-events-none hx:h-4 hx:w-4"&gt;&lt;/div&gt;
&lt;/button&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Assignment 1 Specifics:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Uses shared memory instead of semaphores&lt;/li&gt;
&lt;li&gt;Must manage &lt;code&gt;in&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt; pointers to track buffer positions&lt;/li&gt;
&lt;li&gt;Detect full: &lt;code&gt;(in + 1) % bufSize == out&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Detect empty: &lt;code&gt;in == out&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Use provided functions: &lt;code&gt;GetIn()&lt;/code&gt;, &lt;code&gt;SetIn()&lt;/code&gt;, &lt;code&gt;GetOut()&lt;/code&gt;, &lt;code&gt;SetOut()&lt;/code&gt;, &lt;code&gt;WriteAtBufIndex()&lt;/code&gt;, &lt;code&gt;ReadAtBufIndex()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Structural Changes Analysis:&lt;/strong&gt;
If producer/consumer logic changes (e.g., different wait conditions, modified pointer management), analyze:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What condition causes blocking?&lt;/li&gt;
&lt;li&gt;Does the new structure maintain mutual exclusion?&lt;/li&gt;
&lt;li&gt;Can deadlock or starvation occur?&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Readers-Writers Problem&lt;span class="hx:absolute hx:-mt-20" id="readers-writers-problem"&gt;&lt;/span&gt;
&lt;a href="#readers-writers-problem" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;First Readers-Writers Problem:&lt;/strong&gt;
No reader should wait unless a writer has already obtained permission. Readers have priority; writers may starve.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Second Readers-Writers Problem:&lt;/strong&gt;
Once a writer is ready, it performs its write ASAP. Writers have priority; readers may starve.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When is a Reader-Writer Lock Preferable to a Semaphore?&lt;/strong&gt;
When an application has many more reads than writes. Multiple readers can access data concurrently without conflicts, improving performance over exclusive semaphore access.&lt;/p&gt;
&lt;h4&gt;Dining Philosophers Problem&lt;span class="hx:absolute hx:-mt-20" id="dining-philosophers-problem"&gt;&lt;/span&gt;
&lt;a href="#dining-philosophers-problem" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Monitor Solution Starvation Scenario:&lt;/strong&gt;
A philosopher could starve if their neighbors continually acquire resources before them. For instance, if philosophers 0 and 2 keep eating, philosopher 1 may never get both chopsticks.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;8. Deadlocks&lt;span class="hx:absolute hx:-mt-20" id="8-deadlocks"&gt;&lt;/span&gt;
&lt;a href="#8-deadlocks" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Deadlock Characterization&lt;span class="hx:absolute hx:-mt-20" id="deadlock-characterization"&gt;&lt;/span&gt;
&lt;a href="#deadlock-characterization" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;What is Deadlock?&lt;/strong&gt;
A situation where a set of processes are blocked, each waiting for a resource held by another process in the set. No process can proceed.&lt;/p&gt;
&lt;h3&gt;Four Necessary Conditions for Deadlock&lt;span class="hx:absolute hx:-mt-20" id="four-necessary-conditions-for-deadlock"&gt;&lt;/span&gt;
&lt;a href="#four-necessary-conditions-for-deadlock" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Deadlock can occur only if all four conditions hold simultaneously:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Mutual Exclusion&lt;/strong&gt;
At least one resource must be nonsharable (only one process can use it at a time).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Hold and Wait&lt;/strong&gt;
A process must be holding at least one resource and waiting to acquire additional resources currently held by other processes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;No Preemption&lt;/strong&gt;
Resources cannot be forcibly taken away; they can only be released voluntarily by the process holding them after it completes its task.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Circular Wait&lt;/strong&gt;
A closed chain of processes exists, where each process holds at least one resource needed by the next process in the chain.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Breaking any one condition prevents deadlock.&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;Deadlock Handling Methods&lt;span class="hx:absolute hx:-mt-20" id="deadlock-handling-methods"&gt;&lt;/span&gt;
&lt;a href="#deadlock-handling-methods" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Three General Approaches:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Prevention&lt;/strong&gt;
Ensure at least one of the four necessary conditions cannot hold. Design system to make deadlock impossible.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Avoidance&lt;/strong&gt;
Dynamically examine resource allocation state; only grant requests that keep the system in a safe state. Requires advance knowledge of resource needs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Detection and Recovery / Ignoring&lt;/strong&gt;
Allow deadlocks to occur, then detect and recover. Or ignore (ostrich algorithm) if deadlocks are rare.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Deadlock Prevention Protocols&lt;span class="hx:absolute hx:-mt-20" id="deadlock-prevention-protocols"&gt;&lt;/span&gt;
&lt;a href="#deadlock-prevention-protocols" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Preventing Hold-and-Wait:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Protocol 1:&lt;/strong&gt; Require processes to request and be allocated all resources before execution begins&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protocol 2:&lt;/strong&gt; Allow processes to request resources only when they have none (must release all current resources before requesting new ones)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt; Both cause low resource utilization and potential starvation.&lt;/p&gt;
&lt;h3&gt;Safe and Unsafe States&lt;span class="hx:absolute hx:-mt-20" id="safe-and-unsafe-states"&gt;&lt;/span&gt;
&lt;a href="#safe-and-unsafe-states" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Unsafe State:&lt;/strong&gt;
Does &lt;strong&gt;not&lt;/strong&gt; necessarily lead to deadlock - it means deadlock is &lt;em&gt;possible&lt;/em&gt;. An unsafe state may or may not result in deadlock depending on future resource requests.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Safe State:&lt;/strong&gt;
The system can allocate resources to each process in some order and avoid deadlock. A safe sequence exists.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;9. Memory Management (Real Memory)&lt;span class="hx:absolute hx:-mt-20" id="9-memory-management-real-memory"&gt;&lt;/span&gt;
&lt;a href="#9-memory-management-real-memory" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Address Binding&lt;span class="hx:absolute hx:-mt-20" id="address-binding"&gt;&lt;/span&gt;
&lt;a href="#address-binding" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;When are symbolic addresses bound to physical addresses?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Three Binding Times:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Compile Time&lt;/strong&gt;
If memory location is known at compile time, absolute code is generated. Must recompile if starting location changes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Load Time&lt;/strong&gt;
If memory location is unknown at compile time, compiler generates relocatable code. Binding occurs when the program is loaded.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Execution Time&lt;/strong&gt;
Binding delayed until runtime if process can move during execution. Requires hardware support (base/limit registers). &lt;strong&gt;Most general-purpose OSs use execution time binding&lt;/strong&gt; for flexibility.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Memory Allocation Schemes&lt;span class="hx:absolute hx:-mt-20" id="memory-allocation-schemes"&gt;&lt;/span&gt;
&lt;a href="#memory-allocation-schemes" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;h4&gt;1. Contiguous Allocation&lt;span class="hx:absolute hx:-mt-20" id="1-contiguous-allocation"&gt;&lt;/span&gt;
&lt;a href="#1-contiguous-allocation" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
Each process occupies a single contiguous section of memory.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hardware Support:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Base register&lt;/strong&gt; - Smallest physical address accessible by process&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Limit register&lt;/strong&gt; - Range of logical addresses&lt;/li&gt;
&lt;li&gt;CPU compares every address against these registers for protection&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; Simple, fast access&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Problem:&lt;/strong&gt; &lt;strong&gt;External fragmentation&lt;/strong&gt; - total free memory exists but is scattered in small holes&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2. Segmentation&lt;span class="hx:absolute hx:-mt-20" id="2-segmentation"&gt;&lt;/span&gt;
&lt;a href="#2-segmentation" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
Memory management scheme supporting the user&amp;rsquo;s view of memory. A program is a collection of logical units (segments): main program, procedures, functions, stack, heap, etc.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Logical Address:&lt;/strong&gt;
Two-dimensional: &lt;code&gt;&amp;lt;segment-number, offset&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Segment Table:&lt;/strong&gt;
Maps segment numbers to physical base addresses and limit (length).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; Matches logical structure of programs; can share/protect segments independently&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Still suffers from external fragmentation (segments vary in size)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;3. Paging&lt;span class="hx:absolute hx:-mt-20" id="3-paging"&gt;&lt;/span&gt;
&lt;a href="#3-paging" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
Physical address space can be noncontiguous, eliminating external fragmentation. Physical memory divided into fixed-size &lt;strong&gt;frames&lt;/strong&gt;; logical memory divided into same-size &lt;strong&gt;pages&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Address Translation:&lt;/strong&gt;
Logical address: &lt;code&gt;&amp;lt;page number p, offset d&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Page table&lt;/strong&gt; maps page number to frame number&lt;/li&gt;
&lt;li&gt;Physical address: &lt;code&gt;&amp;lt;frame number, offset&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Calculating Page Number:&lt;/strong&gt;
Given logical address and page size, page number = logical address / page size (integer division).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; Logical address 3085, page size 1024:
Page number = 3085 / 1024 = 3&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Translation Look-aside Buffer (TLB):&lt;/strong&gt;
A fast associative memory cache holding recent page table entries. Speeds up address translation since page tables are typically in main memory.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How does TLB assist translation?&lt;/strong&gt;
TLB stores recent page-to-frame mappings. On a memory reference, the TLB is searched first (in parallel). If found (TLB hit), the frame number is immediately available. If not (TLB miss), the page table must be accessed in main memory.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; No external fragmentation; easy to allocate memory&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Problem:&lt;/strong&gt; &lt;strong&gt;Internal fragmentation&lt;/strong&gt; - allocated memory may be slightly larger than requested (last page may not be full)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Fragmentation&lt;span class="hx:absolute hx:-mt-20" id="fragmentation"&gt;&lt;/span&gt;
&lt;a href="#fragmentation" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;External Fragmentation:&lt;/strong&gt;
Total free memory exists to satisfy a request, but it is scattered in non-contiguous small blocks. Occurs with variable-sized partitions (contiguous allocation, segmentation).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Internal Fragmentation:&lt;/strong&gt;
Allocated memory is slightly larger than requested. The extra memory, internal to a partition, is not used. Occurs with fixed-sized partitions (paging).&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;10. Virtual Memory Management&lt;span class="hx:absolute hx:-mt-20" id="10-virtual-memory-management"&gt;&lt;/span&gt;
&lt;a href="#10-virtual-memory-management" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Virtual Memory Fundamentals&lt;span class="hx:absolute hx:-mt-20" id="virtual-memory-fundamentals"&gt;&lt;/span&gt;
&lt;a href="#virtual-memory-fundamentals" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;What is Virtual Memory?&lt;/strong&gt;
A technique that separates user logical memory from physical memory. Only part of a program needs to be in memory for execution.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Benefits:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Logical address space can be much larger than physical memory&lt;/li&gt;
&lt;li&gt;More programs can run concurrently&lt;/li&gt;
&lt;li&gt;Less I/O needed to load/swap programs&lt;/li&gt;
&lt;li&gt;Faster program loading and response time&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Demand Paging&lt;span class="hx:absolute hx:-mt-20" id="demand-paging"&gt;&lt;/span&gt;
&lt;a href="#demand-paging" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
A page is brought into memory only when it is needed (referenced during execution). The opposite is bringing the entire program into memory at load time.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;When is a page loaded?&lt;/strong&gt;
Only when needed during execution - specifically, when a page fault occurs referencing that page.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Valid-Invalid Bit:&lt;/strong&gt;
Each page table entry has a bit:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Valid (v)&lt;/strong&gt; - Page is in memory (legal and in physical memory)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Invalid (i)&lt;/strong&gt; - Page is not in memory (either illegal or legal but not currently loaded)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Page Fault Sequence:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Reference to invalid page causes a trap to OS (page fault)&lt;/li&gt;
&lt;li&gt;OS checks internal table: invalid reference (abort) or page not in memory?&lt;/li&gt;
&lt;li&gt;If valid reference, find a free frame&lt;/li&gt;
&lt;li&gt;Schedule disk operation to read page into frame&lt;/li&gt;
&lt;li&gt;Update page table (set bit to valid)&lt;/li&gt;
&lt;li&gt;Restart instruction that caused the page fault&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; Reduced memory requirements, faster program startup, more concurrent processes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disadvantage:&lt;/strong&gt; Requires hardware support (page table with valid bit); slow page fault service time&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Effective Access Time (EAT)&lt;span class="hx:absolute hx:-mt-20" id="effective-access-time-eat"&gt;&lt;/span&gt;
&lt;a href="#effective-access-time-eat" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Performance of demand paging depends critically on the &lt;strong&gt;page fault rate (p)&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Formula:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="hextra-code-block hx:relative hx:mt-6 hx:first:mt-0 hx:group/code"&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;EAT = (1 - p) \times memory_access_time &amp;#43; p \times page_fault_service_time&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class="hextra-code-copy-btn-container hx:opacity-0 hx:transition hx:group-hover/code:opacity-100 hx:flex hx:gap-1 hx:absolute hx:m-[11px] hx:right-0 hx:top-0"&gt;
&lt;button
class="hextra-code-copy-btn hx:group/copybtn hx:cursor-pointer hx:transition-all hx:active:opacity-50 hx:bg-primary-700/5 hx:border hx:border-black/5 hx:text-gray-600 hx:hover:text-gray-900 hx:rounded-md hx:p-1.5 hx:dark:bg-primary-300/10 hx:dark:border-white/10 hx:dark:text-gray-400 hx:dark:hover:text-gray-50"
title="Copy code"
&gt;
&lt;div class="hextra-copy-icon hx:group-[.copied]/copybtn:hidden hx:pointer-events-none hx:h-4 hx:w-4"&gt;&lt;/div&gt;
&lt;div class="hextra-success-icon hx:hidden hx:group-[.copied]/copybtn:block hx:pointer-events-none hx:h-4 hx:w-4"&gt;&lt;/div&gt;
&lt;/button&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Memory access: 200 ns&lt;/li&gt;
&lt;li&gt;Page fault service (including disk I/O): 8 ms = 8,000,000 ns&lt;/li&gt;
&lt;li&gt;If p = 0.001 (one fault per 1000 accesses):&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="hextra-code-block hx:relative hx:mt-6 hx:first:mt-0 hx:group/code"&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;EAT = 0.999 \times 200 &amp;#43; 0.001 \times 8,000,000
= 199.8 &amp;#43; 8,000
= 8,199.8 ns&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class="hextra-code-copy-btn-container hx:opacity-0 hx:transition hx:group-hover/code:opacity-100 hx:flex hx:gap-1 hx:absolute hx:m-[11px] hx:right-0 hx:top-0"&gt;
&lt;button
class="hextra-code-copy-btn hx:group/copybtn hx:cursor-pointer hx:transition-all hx:active:opacity-50 hx:bg-primary-700/5 hx:border hx:border-black/5 hx:text-gray-600 hx:hover:text-gray-900 hx:rounded-md hx:p-1.5 hx:dark:bg-primary-300/10 hx:dark:border-white/10 hx:dark:text-gray-400 hx:dark:hover:text-gray-50"
title="Copy code"
&gt;
&lt;div class="hextra-copy-icon hx:group-[.copied]/copybtn:hidden hx:pointer-events-none hx:h-4 hx:w-4"&gt;&lt;/div&gt;
&lt;div class="hextra-success-icon hx:hidden hx:group-[.copied]/copybtn:block hx:pointer-events-none hx:h-4 hx:w-4"&gt;&lt;/div&gt;
&lt;/button&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Performance is 40\times slower than memory access! The page fault rate must be very small for acceptable performance.&lt;/p&gt;
&lt;h3&gt;Page Replacement&lt;span class="hx:absolute hx:-mt-20" id="page-replacement"&gt;&lt;/span&gt;
&lt;a href="#page-replacement" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;When is it needed?&lt;/strong&gt;
When a page fault occurs and no free frames are available in physical memory.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Modify (Dirty) Bit:&lt;/strong&gt;
Indicates whether a page has been modified since loading.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;0 (clean)&lt;/strong&gt; - Page unchanged; no need to write back to disk (discard)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1 (dirty)&lt;/strong&gt; - Page modified; must write back to disk before replacing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;What does the dirty bit signal?&lt;/strong&gt;
The page has been modified since it was loaded into memory and must be saved back to disk if selected as a victim.&lt;/p&gt;
&lt;h3&gt;Page Replacement Algorithms&lt;span class="hx:absolute hx:-mt-20" id="page-replacement-algorithms"&gt;&lt;/span&gt;
&lt;a href="#page-replacement-algorithms" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;h4&gt;1. FIFO (First-In-First-Out)&lt;span class="hx:absolute hx:-mt-20" id="1-fifo-first-in-first-out"&gt;&lt;/span&gt;
&lt;a href="#1-fifo-first-in-first-out" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
Replace the page that has been in memory the longest (oldest).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; Simple to implement&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Problem:&lt;/strong&gt; &lt;strong&gt;Belady&amp;rsquo;s Anomaly&lt;/strong&gt; - increasing the number of frames can sometimes increase the page fault rate&lt;/li&gt;
&lt;li&gt;Poor performance; may replace frequently used pages&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2. Optimal (OPT)&lt;span class="hx:absolute hx:-mt-20" id="2-optimal-opt"&gt;&lt;/span&gt;
&lt;a href="#2-optimal-opt" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
Replace the page that will not be used for the longest period of time in the future.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; Lowest possible page fault rate&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disadvantage:&lt;/strong&gt; Impossible to implement (requires predicting future)&lt;/li&gt;
&lt;li&gt;Used only as a theoretical benchmark for comparison&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;3. Least Recently Used (LRU)&lt;span class="hx:absolute hx:-mt-20" id="3-least-recently-used-lru"&gt;&lt;/span&gt;
&lt;a href="#3-least-recently-used-lru" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
Replace the page that has not been used for the longest time in the past. Uses past behavior to predict future behavior.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; Generally excellent performance; does not suffer from Belady&amp;rsquo;s Anomaly&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disadvantage:&lt;/strong&gt; Requires expensive hardware support to track page usage times (counters or stack for every memory reference)&lt;/li&gt;
&lt;li&gt;Considered one of the best practical algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;4. LRU Approximation (Second-Chance, Clock)&lt;span class="hx:absolute hx:-mt-20" id="4-lru-approximation-second-chance-clock"&gt;&lt;/span&gt;
&lt;a href="#4-lru-approximation-second-chance-clock" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt;
Uses a &lt;strong&gt;reference bit&lt;/strong&gt; for each page. When a page is referenced, its bit is set to 1. For replacement:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Examine pages in FIFO order&lt;/li&gt;
&lt;li&gt;If reference bit = 0, replace this page&lt;/li&gt;
&lt;li&gt;If reference bit = 1, clear it to 0 and check next oldest page&lt;/li&gt;
&lt;li&gt;Give each page a &amp;ldquo;second chance&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantage:&lt;/strong&gt; Efficient approximation of LRU without expensive hardware&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disadvantage:&lt;/strong&gt; Not as effective as true LRU&lt;/li&gt;
&lt;li&gt;Widely used in practice&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Demand Paging vs. Paging with Swapping&lt;span class="hx:absolute hx:-mt-20" id="demand-paging-vs-paging-with-swapping"&gt;&lt;/span&gt;
&lt;a href="#demand-paging-vs-paging-with-swapping" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Demand Paging:&lt;/strong&gt;
Pages are loaded from disk only when referenced (lazy loading). Pages may never be swapped back to disk unless the frame is needed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Paging with Swapping:&lt;/strong&gt;
Entire processes can be swapped out to disk to free memory. When swapped back in, all pages return to memory. More aggressive memory management.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Key Distinction:&lt;/strong&gt; Demand paging is page-level and on-demand; swapping is process-level and typically involves all pages.&lt;/p&gt;
&lt;h3&gt;Thrashing&lt;span class="hx:absolute hx:-mt-20" id="thrashing"&gt;&lt;/span&gt;
&lt;a href="#thrashing" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;What is Thrashing?&lt;/strong&gt;
A state where a process is spending more time paging (swapping pages in and out) than executing. Occurs when a process doesn&amp;rsquo;t have enough frames to hold its &lt;strong&gt;working set&lt;/strong&gt; (the set of pages actively used).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Symptoms:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Low CPU utilization (processes always waiting for page I/O)&lt;/li&gt;
&lt;li&gt;High paging activity&lt;/li&gt;
&lt;li&gt;Severe performance degradation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Why doesn&amp;rsquo;t local replacement entirely solve thrashing?&lt;/strong&gt;
Local replacement (replacing only the process&amp;rsquo;s own pages) prevents one process from stealing frames from others, but doesn&amp;rsquo;t solve the fundamental problem: if a process doesn&amp;rsquo;t have enough frames for its working set, it will thrash regardless of the replacement policy. The only solution is to allocate more frames or reduce the degree of multiprogramming.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Prevention:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Use working set model to allocate sufficient frames&lt;/li&gt;
&lt;li&gt;Use local or priority replacement policies&lt;/li&gt;
&lt;li&gt;Suspend processes if insufficient memory&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;11. Storage Systems and File Systems&lt;span class="hx:absolute hx:-mt-20" id="11-storage-systems-and-file-systems"&gt;&lt;/span&gt;
&lt;a href="#11-storage-systems-and-file-systems" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Disk Scheduling&lt;span class="hx:absolute hx:-mt-20" id="disk-scheduling"&gt;&lt;/span&gt;
&lt;a href="#disk-scheduling" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;h4&gt;Positioning Time Components&lt;span class="hx:absolute hx:-mt-20" id="positioning-time-components"&gt;&lt;/span&gt;
&lt;a href="#positioning-time-components" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Two Components:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Seek Time&lt;/strong&gt; - Time to move the disk arm to the desired cylinder&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rotational Latency&lt;/strong&gt; - Time for the desired sector to rotate under the read/write head&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Total positioning time = seek time + rotational latency&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;Disk Scheduling Algorithms&lt;span class="hx:absolute hx:-mt-20" id="disk-scheduling-algorithms"&gt;&lt;/span&gt;
&lt;a href="#disk-scheduling-algorithms" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;FCFS (First-Come, First-Served):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Description:&lt;/strong&gt; Services requests in arrival order&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Characteristic:&lt;/strong&gt; Ignores current head position&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disadvantage:&lt;/strong&gt; Can result in long waits and inefficient head movement (wild swings across disk)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Other Algorithms (SSTF, SCAN, C-SCAN, LOOK, C-LOOK):&lt;/strong&gt;
Consider head position to minimize seek time and improve throughput.&lt;/p&gt;
&lt;h4&gt;Factors Influencing Algorithm Selection&lt;span class="hx:absolute hx:-mt-20" id="factors-influencing-algorithm-selection"&gt;&lt;/span&gt;
&lt;a href="#factors-influencing-algorithm-selection" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Request arrival patterns&lt;/li&gt;
&lt;li&gt;File allocation methods&lt;/li&gt;
&lt;li&gt;Disk load&lt;/li&gt;
&lt;li&gt;Required response time characteristics&lt;/li&gt;
&lt;li&gt;Fairness vs. efficiency trade-offs&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;File System Implementation&lt;span class="hx:absolute hx:-mt-20" id="file-system-implementation"&gt;&lt;/span&gt;
&lt;a href="#file-system-implementation" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;h4&gt;Structures&lt;span class="hx:absolute hx:-mt-20" id="structures"&gt;&lt;/span&gt;
&lt;a href="#structures" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;On-Disk Structures:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Boot Control Block&lt;/strong&gt; - Information to boot OS from this volume (boot block in UNIX, partition boot sector in Windows)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Volume Control Block&lt;/strong&gt; - Volume/partition details (superblock in UNIX, master file table in NTFS)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Directory Structure&lt;/strong&gt; - Organizes files&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Per-File File Control Block (FCB)&lt;/strong&gt; - File details (inode in UNIX)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Which structure implements a file system?&lt;/strong&gt;
All of the above work together. The boot control block, volume control block, and directory structure are the primary organizational structures.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Which structure reads/writes physical blocks?&lt;/strong&gt;
The &lt;strong&gt;basic file system&lt;/strong&gt; (I/O control layer) issues generic commands to device drivers and reads/writes physical blocks.&lt;/p&gt;
&lt;h4&gt;Allocation Methods&lt;span class="hx:absolute hx:-mt-20" id="allocation-methods"&gt;&lt;/span&gt;
&lt;a href="#allocation-methods" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Linked Allocation:&lt;/strong&gt;
Each file is a linked list of disk blocks scattered anywhere on the disk.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why is the entire block unavailable to the user?&lt;/strong&gt;
Part of each block must be reserved for the pointer to the next block in the chain. If blocks are 512 bytes, and pointers are 4 bytes, only 508 bytes are available for user data per block.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;12. OS Design and Implementation&lt;span class="hx:absolute hx:-mt-20" id="12-os-design-and-implementation"&gt;&lt;/span&gt;
&lt;a href="#12-os-design-and-implementation" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Design Principles&lt;span class="hx:absolute hx:-mt-20" id="design-principles"&gt;&lt;/span&gt;
&lt;a href="#design-principles" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;h4&gt;Policy vs. Mechanism&lt;span class="hx:absolute hx:-mt-20" id="policy-vs-mechanism"&gt;&lt;/span&gt;
&lt;a href="#policy-vs-mechanism" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Critical Design Principle:&lt;/strong&gt;
Separate &lt;strong&gt;policy&lt;/strong&gt; (what will be done?) from &lt;strong&gt;mechanism&lt;/strong&gt; (how to do it?).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mechanism:&lt;/strong&gt;
Determines how to accomplish a task (the implementation details).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Policy:&lt;/strong&gt;
Decides what needs to be done (the decision-making rules).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why separate them?&lt;/strong&gt;
Flexibility - policy changes don&amp;rsquo;t require changing underlying mechanisms. Allows the same OS to adapt to different environments by changing policies without rewriting code.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mechanism:&lt;/strong&gt; Timer interrupt hardware and context switching code&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Policy:&lt;/strong&gt; CPU scheduling algorithm (RR, SJF, Priority)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;OS Structures&lt;span class="hx:absolute hx:-mt-20" id="os-structures"&gt;&lt;/span&gt;
&lt;a href="#os-structures" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;h4&gt;1. Simple Structure (MS-DOS)&lt;span class="hx:absolute hx:-mt-20" id="1-simple-structure-ms-dos"&gt;&lt;/span&gt;
&lt;a href="#1-simple-structure-ms-dos" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Characteristics:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Not divided into modules&lt;/li&gt;
&lt;li&gt;Interfaces and functionality not well separated&lt;/li&gt;
&lt;li&gt;Application programs can access basic I/O routines and hardware directly&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simple to implement initially&lt;/li&gt;
&lt;li&gt;Poor protection and reliability&lt;/li&gt;
&lt;li&gt;Difficult to maintain and extend&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2. Traditional UNIX&lt;span class="hx:absolute hx:-mt-20" id="2-traditional-unix"&gt;&lt;/span&gt;
&lt;a href="#2-traditional-unix" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Characteristics:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Limited structuring&lt;/li&gt;
&lt;li&gt;Two layers: system programs and the kernel&lt;/li&gt;
&lt;li&gt;The kernel is everything below the system-call interface and above hardware&lt;/li&gt;
&lt;li&gt;Monolithic kernel with all services in kernel space&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Efficient (everything in kernel, no message passing overhead)&lt;/li&gt;
&lt;li&gt;Difficult to maintain and extend&lt;/li&gt;
&lt;li&gt;Poor isolation between kernel components&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;3. Microkernel&lt;span class="hx:absolute hx:-mt-20" id="3-microkernel"&gt;&lt;/span&gt;
&lt;a href="#3-microkernel" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Characteristics:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Moves as much functionality as possible out of kernel into user space&lt;/li&gt;
&lt;li&gt;Minimal kernel: IPC, basic scheduling, low-level memory management&lt;/li&gt;
&lt;li&gt;Services communicate via &lt;strong&gt;message passing&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;How do microkernels handle communication?&lt;/strong&gt;
Through &lt;strong&gt;message passing&lt;/strong&gt; - services send messages to each other through the kernel&amp;rsquo;s IPC mechanism.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Assessment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Easier to extend (add services in user space)&lt;/li&gt;
&lt;li&gt;Easier to port to new hardware&lt;/li&gt;
&lt;li&gt;More reliable (service failures don&amp;rsquo;t crash kernel)&lt;/li&gt;
&lt;li&gt;More secure (less code in privileged mode)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Performance overhead due to message passing and user/kernel space transitions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;4. Hybrid Systems&lt;span class="hx:absolute hx:-mt-20" id="4-hybrid-systems"&gt;&lt;/span&gt;
&lt;a href="#4-hybrid-systems" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Characteristics:&lt;/strong&gt;
Most modern OSs combine multiple approaches for practical reasons.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Linux/Solaris:&lt;/strong&gt; Monolithic kernel with loadable modules&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mac OS X:&lt;/strong&gt; Mach microkernel foundation + BSD UNIX components + other layers&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Windows:&lt;/strong&gt; Modular monolithic kernel with some microkernel concepts&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;13. Assignment 1 - Shared Memory Producer-Consumer&lt;span class="hx:absolute hx:-mt-20" id="13-assignment-1---shared-memory-producer-consumer"&gt;&lt;/span&gt;
&lt;a href="#13-assignment-1---shared-memory-producer-consumer" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Overview&lt;span class="hx:absolute hx:-mt-20" id="overview"&gt;&lt;/span&gt;
&lt;a href="#overview" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Implement producer and consumer programs that communicate through a &lt;strong&gt;bounded buffer in shared memory&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;Key Components&lt;span class="hx:absolute hx:-mt-20" id="key-components"&gt;&lt;/span&gt;
&lt;a href="#key-components" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;h4&gt;Shared Memory Structure (4KB block)&lt;span class="hx:absolute hx:-mt-20" id="shared-memory-structure-4kb-block"&gt;&lt;/span&gt;
&lt;a href="#shared-memory-structure-4kb-block" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Header:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;bufSize&lt;/code&gt; - Buffer capacity (number of items)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;itemCnt&lt;/code&gt; - Total items to produce/consume&lt;/li&gt;
&lt;li&gt;&lt;code&gt;in&lt;/code&gt; - Index where next item will be produced&lt;/li&gt;
&lt;li&gt;&lt;code&gt;out&lt;/code&gt; - Index where next item will be consumed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Buffer Area:&lt;/strong&gt;
Contains the actual data items following the header.&lt;/p&gt;
&lt;h3&gt;Process Creation&lt;span class="hx:absolute hx:-mt-20" id="process-creation-1"&gt;&lt;/span&gt;
&lt;a href="#process-creation-1" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Producer (parent)&lt;/strong&gt; creates shared memory using &lt;code&gt;InitShm()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Producer uses &lt;code&gt;fork()&lt;/code&gt; to create &lt;strong&gt;Consumer (child)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Producer uses &lt;code&gt;exec()&lt;/code&gt; to load consumer executable&lt;/li&gt;
&lt;li&gt;Child inherits access to shared memory&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Synchronization Requirements&lt;span class="hx:absolute hx:-mt-20" id="synchronization-requirements"&gt;&lt;/span&gt;
&lt;a href="#synchronization-requirements" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Buffer Full Condition:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="hextra-code-block hx:relative hx:mt-6 hx:first:mt-0 hx:group/code"&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;(in &amp;#43; 1) % bufSize == out&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class="hextra-code-copy-btn-container hx:opacity-0 hx:transition hx:group-hover/code:opacity-100 hx:flex hx:gap-1 hx:absolute hx:m-[11px] hx:right-0 hx:top-0"&gt;
&lt;button
class="hextra-code-copy-btn hx:group/copybtn hx:cursor-pointer hx:transition-all hx:active:opacity-50 hx:bg-primary-700/5 hx:border hx:border-black/5 hx:text-gray-600 hx:hover:text-gray-900 hx:rounded-md hx:p-1.5 hx:dark:bg-primary-300/10 hx:dark:border-white/10 hx:dark:text-gray-400 hx:dark:hover:text-gray-50"
title="Copy code"
&gt;
&lt;div class="hextra-copy-icon hx:group-[.copied]/copybtn:hidden hx:pointer-events-none hx:h-4 hx:w-4"&gt;&lt;/div&gt;
&lt;div class="hextra-success-icon hx:hidden hx:group-[.copied]/copybtn:block hx:pointer-events-none hx:h-4 hx:w-4"&gt;&lt;/div&gt;
&lt;/button&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Producer must &lt;strong&gt;wait&lt;/strong&gt; if buffer is full before producing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Buffer Empty Condition:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="hextra-code-block hx:relative hx:mt-6 hx:first:mt-0 hx:group/code"&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;in == out&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class="hextra-code-copy-btn-container hx:opacity-0 hx:transition hx:group-hover/code:opacity-100 hx:flex hx:gap-1 hx:absolute hx:m-[11px] hx:right-0 hx:top-0"&gt;
&lt;button
class="hextra-code-copy-btn hx:group/copybtn hx:cursor-pointer hx:transition-all hx:active:opacity-50 hx:bg-primary-700/5 hx:border hx:border-black/5 hx:text-gray-600 hx:hover:text-gray-900 hx:rounded-md hx:p-1.5 hx:dark:bg-primary-300/10 hx:dark:border-white/10 hx:dark:text-gray-400 hx:dark:hover:text-gray-50"
title="Copy code"
&gt;
&lt;div class="hextra-copy-icon hx:group-[.copied]/copybtn:hidden hx:pointer-events-none hx:h-4 hx:w-4"&gt;&lt;/div&gt;
&lt;div class="hextra-success-icon hx:hidden hx:group-[.copied]/copybtn:block hx:pointer-events-none hx:h-4 hx:w-4"&gt;&lt;/div&gt;
&lt;/button&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Consumer must &lt;strong&gt;wait&lt;/strong&gt; if buffer is empty before consuming.&lt;/p&gt;
&lt;h3&gt;Required Functions&lt;span class="hx:absolute hx:-mt-20" id="required-functions"&gt;&lt;/span&gt;
&lt;a href="#required-functions" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Pointer Management:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;GetIn()&lt;/code&gt; - Read current &lt;code&gt;in&lt;/code&gt; value&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SetIn(new_value)&lt;/code&gt; - Update &lt;code&gt;in&lt;/code&gt; value&lt;/li&gt;
&lt;li&gt;&lt;code&gt;GetOut()&lt;/code&gt; - Read current &lt;code&gt;out&lt;/code&gt; value&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SetOut(new_value)&lt;/code&gt; - Update &lt;code&gt;out&lt;/code&gt; value&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Buffer Access:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;WriteAtBufIndex(index, data)&lt;/code&gt; - Write data at buffer index&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ReadAtBufIndex(index)&lt;/code&gt; - Read data from buffer index&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Critical:&lt;/strong&gt; Use these functions to maintain synchronization and avoid race conditions.&lt;/p&gt;
&lt;h3&gt;Implementation Tips&lt;span class="hx:absolute hx:-mt-20" id="implementation-tips"&gt;&lt;/span&gt;
&lt;a href="#implementation-tips" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;Always check buffer full/empty before producing/consuming&lt;/li&gt;
&lt;li&gt;Use modulo arithmetic for circular buffer indices&lt;/li&gt;
&lt;li&gt;Produce/consume one item at a time&lt;/li&gt;
&lt;li&gt;Update &lt;code&gt;in&lt;/code&gt;/&lt;code&gt;out&lt;/code&gt; pointers after each operation&lt;/li&gt;
&lt;li&gt;Handle the case where &lt;code&gt;itemCnt&lt;/code&gt; items have been processed&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;14. Assignment 2 - CPU Scheduling Simulation&lt;span class="hx:absolute hx:-mt-20" id="14-assignment-2---cpu-scheduling-simulation"&gt;&lt;/span&gt;
&lt;a href="#14-assignment-2---cpu-scheduling-simulation" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Overview&lt;span class="hx:absolute hx:-mt-20" id="overview-1"&gt;&lt;/span&gt;
&lt;a href="#overview-1" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Simulate four CPU scheduling algorithms on a single CPU system, reading process data from input and producing scheduling statistics.&lt;/p&gt;
&lt;h3&gt;Input Format&lt;span class="hx:absolute hx:-mt-20" id="input-format"&gt;&lt;/span&gt;
&lt;a href="#input-format" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Each process has:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Arrival time&lt;/li&gt;
&lt;li&gt;CPU burst length&lt;/li&gt;
&lt;li&gt;Priority (for priority scheduling)&lt;/li&gt;
&lt;li&gt;Process ID&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Algorithms to Implement&lt;span class="hx:absolute hx:-mt-20" id="algorithms-to-implement"&gt;&lt;/span&gt;
&lt;a href="#algorithms-to-implement" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;h4&gt;1. Round Robin (RR)&lt;span class="hx:absolute hx:-mt-20" id="1-round-robin-rr"&gt;&lt;/span&gt;
&lt;a href="#1-round-robin-rr" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt; Time quantum (given)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Algorithm:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Maintain FIFO ready queue&lt;/li&gt;
&lt;li&gt;Add arriving processes to queue in arrival order&lt;/li&gt;
&lt;li&gt;Execute front process for quantum or until completion&lt;/li&gt;
&lt;li&gt;If quantum expires, preempt and add to end of queue&lt;/li&gt;
&lt;li&gt;Repeat until all processes complete&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Special Cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Process completes before quantum expires&lt;/li&gt;
&lt;li&gt;Multiple processes arrive at same time (add in input order)&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;2. Shortest Job First (SJF) - Non-preemptive&lt;span class="hx:absolute hx:-mt-20" id="2-shortest-job-first-sjf---non-preemptive"&gt;&lt;/span&gt;
&lt;a href="#2-shortest-job-first-sjf---non-preemptive" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Algorithm:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Scheduling decisions only when current process terminates&lt;/li&gt;
&lt;li&gt;Select process from ready queue with shortest CPU burst&lt;/li&gt;
&lt;li&gt;Ties broken by arrival time (FCFS)&lt;/li&gt;
&lt;li&gt;Execute selected process to completion&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Key:&lt;/strong&gt; Once a process starts, it runs to completion (non-preemptive).&lt;/p&gt;
&lt;h4&gt;3. Priority Scheduling - No Preemption&lt;span class="hx:absolute hx:-mt-20" id="3-priority-scheduling---no-preemption"&gt;&lt;/span&gt;
&lt;a href="#3-priority-scheduling---no-preemption" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Algorithm:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Scheduling decisions only when current process terminates&lt;/li&gt;
&lt;li&gt;Select process from ready queue with highest priority (smallest number)&lt;/li&gt;
&lt;li&gt;Ties broken arbitrarily&lt;/li&gt;
&lt;li&gt;Execute selected process to completion&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;4. Priority Scheduling - With Preemption&lt;span class="hx:absolute hx:-mt-20" id="4-priority-scheduling---with-preemption"&gt;&lt;/span&gt;
&lt;a href="#4-priority-scheduling---with-preemption" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Algorithm:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Scheduling decisions on termination OR when higher priority arrives&lt;/li&gt;
&lt;li&gt;When new process arrives:
&lt;ul&gt;
&lt;li&gt;If its priority &amp;gt; current process priority, preempt current process&lt;/li&gt;
&lt;li&gt;Add preempted process back to ready queue&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Select highest priority ready process&lt;/li&gt;
&lt;li&gt;Execute until completion or preemption&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Key Difference:&lt;/strong&gt; Can interrupt running process if higher priority arrives.&lt;/p&gt;
&lt;h3&gt;Output Requirements&lt;span class="hx:absolute hx:-mt-20" id="output-requirements"&gt;&lt;/span&gt;
&lt;a href="#output-requirements" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;For each algorithm, calculate and report:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Completion time&lt;/strong&gt; for each process&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Turnaround time&lt;/strong&gt; (completion - arrival)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Waiting time&lt;/strong&gt; (turnaround - burst)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Average turnaround time&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Average waiting time&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Gantt chart&lt;/strong&gt; showing process execution timeline&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Implementation Considerations&lt;span class="hx:absolute hx:-mt-20" id="implementation-considerations"&gt;&lt;/span&gt;
&lt;a href="#implementation-considerations" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Event-driven simulation&lt;/strong&gt; - Process events in time order (arrivals, completions, quantum expirations)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ready queue management&lt;/strong&gt; - Different data structures for different algorithms (FIFO queue, priority queue, sorted list)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Context switching&lt;/strong&gt; - Track when processes start/stop&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tie-breaking&lt;/strong&gt; - Be consistent with specified rules&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Edge cases&lt;/strong&gt; - Multiple simultaneous events, idle CPU time&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2&gt;15. Quick Reference Tables&lt;span class="hx:absolute hx:-mt-20" id="15-quick-reference-tables"&gt;&lt;/span&gt;
&lt;a href="#15-quick-reference-tables" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Process States Summary&lt;span class="hx:absolute hx:-mt-20" id="process-states-summary"&gt;&lt;/span&gt;
&lt;a href="#process-states-summary" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Transition&lt;/th&gt;
&lt;th&gt;Trigger&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;New â†’ Ready&lt;/td&gt;
&lt;td&gt;Process admitted&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ready â†’ Running&lt;/td&gt;
&lt;td&gt;Scheduler selects process&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Running â†’ Waiting&lt;/td&gt;
&lt;td&gt;I/O request or event wait&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Running â†’ Ready&lt;/td&gt;
&lt;td&gt;Interrupt (timer, preemption)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Waiting â†’ Ready&lt;/td&gt;
&lt;td&gt;I/O or event completion&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Running â†’ Terminated&lt;/td&gt;
&lt;td&gt;Process exits&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;Scheduling Algorithm Selection Guide&lt;span class="hx:absolute hx:-mt-20" id="scheduling-algorithm-selection-guide"&gt;&lt;/span&gt;
&lt;a href="#scheduling-algorithm-selection-guide" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Algorithm&lt;/th&gt;
&lt;th&gt;Best For&lt;/th&gt;
&lt;th&gt;Worst For&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;FCFS&lt;/td&gt;
&lt;td&gt;Simple batch systems&lt;/td&gt;
&lt;td&gt;Interactive systems (convoy effect)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SJF/SRTF&lt;/td&gt;
&lt;td&gt;Minimizing average waiting time&lt;/td&gt;
&lt;td&gt;Long processes (starvation risk)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Priority&lt;/td&gt;
&lt;td&gt;Important tasks need preference&lt;/td&gt;
&lt;td&gt;Ensuring fairness (starvation risk)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;RR&lt;/td&gt;
&lt;td&gt;Interactive systems, time-sharing&lt;/td&gt;
&lt;td&gt;Minimizing turnaround time&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Multilevel Feedback&lt;/td&gt;
&lt;td&gt;Mixed workloads (interactive + CPU-bound)&lt;/td&gt;
&lt;td&gt;Simplicity of implementation&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;Synchronization Tool Comparison&lt;span class="hx:absolute hx:-mt-20" id="synchronization-tool-comparison"&gt;&lt;/span&gt;
&lt;a href="#synchronization-tool-comparison" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Tool&lt;/th&gt;
&lt;th&gt;Complexity&lt;/th&gt;
&lt;th&gt;Requires Hardware&lt;/th&gt;
&lt;th&gt;Busy Waiting&lt;/th&gt;
&lt;th&gt;Best Use&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Mutex Lock&lt;/td&gt;
&lt;td&gt;Low&lt;/td&gt;
&lt;td&gt;Yes (atomic ops)&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Simple mutual exclusion&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Binary Semaphore&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;Yes (atomic ops)&lt;/td&gt;
&lt;td&gt;Optional&lt;/td&gt;
&lt;td&gt;Mutual exclusion&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Counting Semaphore&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;td&gt;Yes (atomic ops)&lt;/td&gt;
&lt;td&gt;Optional&lt;/td&gt;
&lt;td&gt;Resource counting&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Monitor&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;td&gt;No (language support)&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Complex synchronization&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;Memory Management Comparison&lt;span class="hx:absolute hx:-mt-20" id="memory-management-comparison"&gt;&lt;/span&gt;
&lt;a href="#memory-management-comparison" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Scheme&lt;/th&gt;
&lt;th&gt;Fragmentation&lt;/th&gt;
&lt;th&gt;Address Translation&lt;/th&gt;
&lt;th&gt;Flexibility&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Contiguous&lt;/td&gt;
&lt;td&gt;External&lt;/td&gt;
&lt;td&gt;Base/Limit registers&lt;/td&gt;
&lt;td&gt;Low&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Segmentation&lt;/td&gt;
&lt;td&gt;External&lt;/td&gt;
&lt;td&gt;Segment table&lt;/td&gt;
&lt;td&gt;Medium&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Paging&lt;/td&gt;
&lt;td&gt;Internal&lt;/td&gt;
&lt;td&gt;Page table&lt;/td&gt;
&lt;td&gt;High&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Virtual Memory&lt;/td&gt;
&lt;td&gt;Internal&lt;/td&gt;
&lt;td&gt;Page table + disk&lt;/td&gt;
&lt;td&gt;Highest&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2&gt;16. Common Exam Question Patterns&lt;span class="hx:absolute hx:-mt-20" id="16-common-exam-question-patterns"&gt;&lt;/span&gt;
&lt;a href="#16-common-exam-question-patterns" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Calculation Problems&lt;span class="hx:absolute hx:-mt-20" id="calculation-problems"&gt;&lt;/span&gt;
&lt;a href="#calculation-problems" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;1. Page Number from Logical Address:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Page number = logical_address / page_size (integer division)&lt;/li&gt;
&lt;li&gt;Offset = logical_address % page_size&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. Context Switch Time with Swapping:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="hextra-code-block hx:relative hx:mt-6 hx:first:mt-0 hx:group/code"&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;Total time = 2 \times (swap_out_time &amp;#43; swap_in_time) &amp;#43; actual_context_switch
Swap time = (process_size / transfer_rate) &amp;#43; latency&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class="hextra-code-copy-btn-container hx:opacity-0 hx:transition hx:group-hover/code:opacity-100 hx:flex hx:gap-1 hx:absolute hx:m-[11px] hx:right-0 hx:top-0"&gt;
&lt;button
class="hextra-code-copy-btn hx:group/copybtn hx:cursor-pointer hx:transition-all hx:active:opacity-50 hx:bg-primary-700/5 hx:border hx:border-black/5 hx:text-gray-600 hx:hover:text-gray-900 hx:rounded-md hx:p-1.5 hx:dark:bg-primary-300/10 hx:dark:border-white/10 hx:dark:text-gray-400 hx:dark:hover:text-gray-50"
title="Copy code"
&gt;
&lt;div class="hextra-copy-icon hx:group-[.copied]/copybtn:hidden hx:pointer-events-none hx:h-4 hx:w-4"&gt;&lt;/div&gt;
&lt;div class="hextra-success-icon hx:hidden hx:group-[.copied]/copybtn:block hx:pointer-events-none hx:h-4 hx:w-4"&gt;&lt;/div&gt;
&lt;/button&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;3. Effective Access Time:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="hextra-code-block hx:relative hx:mt-6 hx:first:mt-0 hx:group/code"&gt;
&lt;div&gt;&lt;pre&gt;&lt;code&gt;EAT = (1 - p) \times mem_access &amp;#43; p \times page_fault_time&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class="hextra-code-copy-btn-container hx:opacity-0 hx:transition hx:group-hover/code:opacity-100 hx:flex hx:gap-1 hx:absolute hx:m-[11px] hx:right-0 hx:top-0"&gt;
&lt;button
class="hextra-code-copy-btn hx:group/copybtn hx:cursor-pointer hx:transition-all hx:active:opacity-50 hx:bg-primary-700/5 hx:border hx:border-black/5 hx:text-gray-600 hx:hover:text-gray-900 hx:rounded-md hx:p-1.5 hx:dark:bg-primary-300/10 hx:dark:border-white/10 hx:dark:text-gray-400 hx:dark:hover:text-gray-50"
title="Copy code"
&gt;
&lt;div class="hextra-copy-icon hx:group-[.copied]/copybtn:hidden hx:pointer-events-none hx:h-4 hx:w-4"&gt;&lt;/div&gt;
&lt;div class="hextra-success-icon hx:hidden hx:group-[.copied]/copybtn:block hx:pointer-events-none hx:h-4 hx:w-4"&gt;&lt;/div&gt;
&lt;/button&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h3&gt;Conceptual Questions&lt;span class="hx:absolute hx:-mt-20" id="conceptual-questions"&gt;&lt;/span&gt;
&lt;a href="#conceptual-questions" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Operating System as Government:&lt;/strong&gt;
Creates environment for programs to work; manages resources; doesn&amp;rsquo;t do productive work itself.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Items Shared by Threads:&lt;/strong&gt;
Code, data, files. Each thread has its own: PC, registers, stack.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why Google Chrome Uses Multiple Processes:&lt;/strong&gt;
Isolation for stability and security; tab/plugin crashes don&amp;rsquo;t affect others.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aging Purpose:&lt;/strong&gt;
Prevents starvation by gradually increasing priority of waiting processes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thrashing:&lt;/strong&gt;
Excessive paging; process doesn&amp;rsquo;t have enough frames for working set; CPU utilization drops.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Key Takeaways for Assignments&lt;span class="hx:absolute hx:-mt-20" id="key-takeaways-for-assignments"&gt;&lt;/span&gt;
&lt;a href="#key-takeaways-for-assignments" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;Assignment 1 Success Factors&lt;span class="hx:absolute hx:-mt-20" id="assignment-1-success-factors"&gt;&lt;/span&gt;
&lt;a href="#assignment-1-success-factors" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;[CHECK] Understand circular buffer logic
[CHECK] Check full/empty conditions correctly
[CHECK] Use provided functions exclusively
[CHECK] Handle synchronization with shared variables
[CHECK] Test with various buffer sizes and item counts&lt;/p&gt;
&lt;h3&gt;Assignment 2 Success Factors&lt;span class="hx:absolute hx:-mt-20" id="assignment-2-success-factors"&gt;&lt;/span&gt;
&lt;a href="#assignment-2-success-factors" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;[CHECK] Implement event-driven simulation
[CHECK] Use appropriate data structures for each algorithm
[CHECK] Handle tie-breaking consistently
[CHECK] Track all timing information accurately
[CHECK] Test with edge cases (simultaneous arrivals, process completion timing)
[CHECK] Verify calculations match algorithm specifications&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;End of Study Guide&lt;/em&gt;&lt;/p&gt;</description></item><item><title/><link>https://erauredeyesociety.github.io/electrical_notes/cs_420/ass1_ass2_topics_noteboooklm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://erauredeyesociety.github.io/electrical_notes/cs_420/ass1_ass2_topics_noteboooklm/</guid><description>
&lt;p&gt;This documentation outlines the core theoretical concepts relevant to Assignments 1 and 2, based on the course description and included materials. The purpose of this course is two-fold: to provide an understanding of the concepts and design of operating systems (OS), and to examine implementation details of OSs like UNIX and Windows.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Operating Systems Theory Outline&lt;span class="hx:absolute hx:-mt-20" id="operating-systems-theory-outline"&gt;&lt;/span&gt;
&lt;a href="#operating-systems-theory-outline" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;h3&gt;I. Functions of an Operating System&lt;span class="hx:absolute hx:-mt-20" id="i-functions-of-an-operating-system"&gt;&lt;/span&gt;
&lt;a href="#i-functions-of-an-operating-system" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;An operating system acts as an intermediary program between a user and the computer hardware.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Primary Goals and Roles (Describe the functions of an operating system):&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Execute user programs&lt;/strong&gt; and make solving user problems easier.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Make the computer system convenient to use&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use the computer hardware efficiently&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Resource Allocator:&lt;/strong&gt; The OS manages all resources and decides between conflicting requests to ensure efficient and fair resource use.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Control Program:&lt;/strong&gt; The OS controls the execution of programs to prevent errors and improper use of the computer.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Key Operating System Services:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;User Interface (UI):&lt;/strong&gt; Nearly all OSs provide a user interface, which can be Command-Line (CLI), Graphics User Interface (GUI), or Batch.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Program Execution:&lt;/strong&gt; The system must load a program into memory, run it, and handle termination (normal or error).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;I/O Operations:&lt;/strong&gt; Managing I/O requests, which may involve files or I/O devices.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;File-System Manipulation:&lt;/strong&gt; Programs need to read, write, create, delete, search files and directories, list information, and manage permissions.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Communications (IPC):&lt;/strong&gt; Processes exchange information either on the same computer or over a network, potentially using &lt;strong&gt;shared memory&lt;/strong&gt; or &lt;strong&gt;message passing&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Error Detection:&lt;/strong&gt; The OS must constantly be aware of errors in the CPU, memory, I/O devices, or user programs, and take appropriate action to ensure consistent computing.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Resource Allocation:&lt;/strong&gt; When multiple jobs run concurrently, the OS allocates resources such as CPU cycles, main memory, file storage, and I/O devices.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Protection and Security:&lt;/strong&gt; Protection ensures access to system resources is controlled, while security defends the system (and user information) from external invalid access attempts.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3&gt;II. Interrupt Handling (Describe the events that follow the occurrence of an interrupt)&lt;span class="hx:absolute hx:-mt-20" id="ii-interrupt-handling-describe-the-events-that-follow-the-occurrence-of-an-interrupt"&gt;&lt;/span&gt;
&lt;a href="#ii-interrupt-handling-describe-the-events-that-follow-the-occurrence-of-an-interrupt" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;The operating system is fundamentally &lt;strong&gt;interrupt driven&lt;/strong&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Interrupt Trigger:&lt;/strong&gt; An I/O device controller informs the CPU that it has finished an operation by causing a hardware interrupt. Alternatively, a &lt;strong&gt;trap&lt;/strong&gt; or &lt;strong&gt;exception&lt;/strong&gt; is a software-generated interrupt caused by an error (e.g., division by zero) or a user request (e.g., a system call).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Control Transfer:&lt;/strong&gt; The interrupt transfers control to the &lt;strong&gt;interrupt service routine&lt;/strong&gt;. This transfer is generally achieved through the &lt;strong&gt;interrupt vector&lt;/strong&gt;, which contains the memory addresses of all the service routines.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;State Preservation:&lt;/strong&gt; The interrupt architecture must save the address of the interrupted instruction so the system can resume execution later. User program registers and process state are saved.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kernel Mode Entry:&lt;/strong&gt; If the interrupt is a request for an OS service (a system call), the mode bit is changed to &lt;strong&gt;kernel mode&lt;/strong&gt; (or supervisor mode), allowing privileged instructions to execute.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Service Routine Execution:&lt;/strong&gt; The CPU executes the relevant service routine based on the interrupt type.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Return to User:&lt;/strong&gt; After the interrupt is handled, the system call changes the mode back to user mode, and execution resumes from the saved instruction address.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A &lt;strong&gt;timer&lt;/strong&gt; can be set by the operating system (a privileged instruction) to interrupt the computer after a certain period, ensuring the OS regains control and preventing a single process from hogging resources.&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;III. Process and Thread Management Schemes&lt;span class="hx:absolute hx:-mt-20" id="iii-process-and-thread-management-schemes"&gt;&lt;/span&gt;
&lt;a href="#iii-process-and-thread-management-schemes" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;A. Process Management (Describe and Assess)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A &lt;strong&gt;process&lt;/strong&gt; is defined as a program in execution and is the unit of work within the system; a program is merely a passive entity.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left"&gt;Component&lt;/th&gt;
&lt;th style="text-align: left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Process State&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Changes as the process executes: &lt;em&gt;new&lt;/em&gt;, &lt;em&gt;running&lt;/em&gt;, &lt;em&gt;waiting&lt;/em&gt; (for an event), &lt;em&gt;ready&lt;/em&gt; (waiting for a processor), or &lt;em&gt;terminated&lt;/em&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Process Control Block (PCB)&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Information associated with each process, including state, program counter, CPU registers, scheduling information, memory management data, accounting info, and I/O status.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Process Creation&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Parent processes create children processes, forming a tree. The UNIX &lt;code&gt;fork()&lt;/code&gt; system call creates a new process, and &lt;code&gt;exec()&lt;/code&gt; replaces the child process&amp;rsquo;s memory space with a new program.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Interprocess Communication (IPC)&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Cooperating processes need mechanisms to share information, achieve computation speedup, or maintain modularity. This is achieved via &lt;strong&gt;shared memory&lt;/strong&gt; or &lt;strong&gt;message passing&lt;/strong&gt;.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;B. Thread Management (Describe and Assess)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A thread is a fundamental unit of CPU utilization. A multithreaded process has one program counter per thread, allowing multiple locations to execute at once.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left"&gt;Benefit&lt;/th&gt;
&lt;th style="text-align: left"&gt;Description / Assessment&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Responsiveness&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Allows continued execution if part of the process is blocked (important for UIs).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Resource Sharing&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Threads automatically share the resources of the parent process, which is easier than implementing shared memory or message passing between separate processes.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Economy&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Thread creation is &amp;ldquo;light-weight&amp;rdquo; and cheaper than &amp;ldquo;heavy-weight&amp;rdquo; process creation; thread switching has lower overhead than context switching.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Scalability&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;A process can take advantage of multiprocessor architectures (parallelism).&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Multithreading Models (Explain the major alternatives for process/thread management):&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left"&gt;Model&lt;/th&gt;
&lt;th style="text-align: left"&gt;Description&lt;/th&gt;
&lt;th style="text-align: left"&gt;Assessment / Usage&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;User Threads&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Management done by user-level thread libraries (e.g., POSIX Pthreads, Windows threads, Java threads).&lt;/td&gt;
&lt;td style="text-align: left"&gt;Kernel is unaware of them.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Kernel Threads&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Supported directly by the operating system kernel (e.g., Windows, Linux, Solaris).&lt;/td&gt;
&lt;td style="text-align: left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Many-to-One&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Many user threads mapped to a single kernel thread.&lt;/td&gt;
&lt;td style="text-align: left"&gt;Low concurrency; if one thread blocks, all block. Few systems use this.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;One-to-One&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Each user thread maps to a separate kernel thread.&lt;/td&gt;
&lt;td style="text-align: left"&gt;Higher concurrency, commonly used (e.g., Windows, Linux). Overhead may restrict the total number of threads.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Many-to-Many&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Many user threads mapped to a smaller or equal number of kernel threads.&lt;/td&gt;
&lt;td style="text-align: left"&gt;Allows the OS to create a sufficient number of kernel threads for optimal execution.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3&gt;IV. Concurrency Mechanisms (Use semaphores and other mechanisms to solve standard concurrency problems)&lt;span class="hx:absolute hx:-mt-20" id="iv-concurrency-mechanisms-use-semaphores-and-other-mechanisms-to-solve-standard-concurrency-problems"&gt;&lt;/span&gt;
&lt;a href="#iv-concurrency-mechanisms-use-semaphores-and-other-mechanisms-to-solve-standard-concurrency-problems" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Concurrency&lt;/strong&gt; supports more than one task making progress, typically achieved by multiplexing CPUs among processes/threads. &lt;strong&gt;Parallelism&lt;/strong&gt; implies a system can perform more than one task simultaneously, requiring multi-core hardware.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Race Condition:&lt;/strong&gt; Occurs when several processes concurrently access and manipulate the same data, and the final outcome depends on the particular order in which the access takes place. Maintaining data consistency requires orderly execution of cooperating processes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Critical Section (CS) Requirements:&lt;/strong&gt; Any solution designed to solve the critical-section problem must satisfy three requirements:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Mutual Exclusion:&lt;/strong&gt; If process &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;P_i&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class="katex-html" aria-hidden="true"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.8333em;vertical-align:-0.15em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathnormal" style="margin-right:0.13889em;"&gt;P&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist" style="height:0.3117em;"&gt;&lt;span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"&gt;&lt;span class="pstrut" style="height:2.7em;"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mathnormal mtight"&gt;i&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;â€‹&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist" style="height:0.15em;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is executing in its critical section, no other process can be executing in their critical sections.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Progress:&lt;/strong&gt; If no process is in the CS, and some wish to enter, the selection of the next process cannot be postponed indefinitely.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bounded Waiting:&lt;/strong&gt; A limit must exist on the number of times other processes can enter their CS after a process requests entry, but before that request is granted.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Synchronization Tools (Describe and Assess):&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left"&gt;Mechanism&lt;/th&gt;
&lt;th style="text-align: left"&gt;Description&lt;/th&gt;
&lt;th style="text-align: left"&gt;Assessment / Usage&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Mutex Locks&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Simplest software tool. Protects a CS by requiring a process to &lt;code&gt;acquire()&lt;/code&gt; a lock before entering and &lt;code&gt;release()&lt;/code&gt; the lock upon exiting.&lt;/td&gt;
&lt;td style="text-align: left"&gt;Requires busy waiting (spinlock). Calls to &lt;code&gt;acquire()&lt;/code&gt; and &lt;code&gt;release()&lt;/code&gt; must be atomic.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Semaphores&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;An integer variable, &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;S&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;S&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class="katex-html" aria-hidden="true"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.6833em;"&gt;&lt;/span&gt;&lt;span class="mord mathnormal" style="margin-right:0.05764em;"&gt;S&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, accessed only via atomic &lt;code&gt;wait()&lt;/code&gt; (decrement) and &lt;code&gt;signal()&lt;/code&gt; (increment) operations.&lt;/td&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Counting Semaphores&lt;/strong&gt; range over an unrestricted domain and can control access to a resource with a finite number of instances. &lt;strong&gt;Binary Semaphores&lt;/strong&gt; are equivalent to mutex locks (range 0 or 1). Can be implemented without busy waiting using a waiting queue.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Monitors&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;A high-level abstraction (Abstract Data Type) ensuring that only one process may be active within the monitor procedures at a time.&lt;/td&gt;
&lt;td style="text-align: left"&gt;Uses &lt;strong&gt;condition variables&lt;/strong&gt; (&lt;code&gt;x.wait()&lt;/code&gt;, &lt;code&gt;x.signal()&lt;/code&gt;) to suspend and resume processes within the monitor structure.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Standard Concurrency Problem: Bounded-Buffer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The classic Producer-Consumer problem using a bounded buffer can be solved using three semaphores:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;mutex&lt;/code&gt;: Initialized to 1, ensuring mutual exclusion for buffer access.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;full&lt;/code&gt;: Initialized to 0, counting the number of full buffers.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;empty&lt;/code&gt;: Initialized to &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;n&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;n&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class="katex-html" aria-hidden="true"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.4306em;"&gt;&lt;/span&gt;&lt;span class="mord mathnormal"&gt;n&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; (buffer size), counting the number of empty buffers.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The &lt;strong&gt;Producer&lt;/strong&gt; must &lt;code&gt;wait(empty)&lt;/code&gt; (wait if buffer is full) before adding an item, and the &lt;strong&gt;Consumer&lt;/strong&gt; must &lt;code&gt;wait(full)&lt;/code&gt; (wait if buffer is empty) before removing an item. Both use &lt;code&gt;wait(mutex)&lt;/code&gt; and &lt;code&gt;signal(mutex)&lt;/code&gt; around buffer access (the critical section). (Assignment 1 requires implementing the bounded buffer producer/consumer using shared memory and managing the buffer pointers &lt;code&gt;in&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt; to detect full/empty conditions.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Deadlock Characterization:&lt;/strong&gt; Deadlock can arise if four conditions hold simultaneously:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Mutual Exclusion:&lt;/strong&gt; Only one process can use a resource at a time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hold and Wait:&lt;/strong&gt; A process holding at least one resource is waiting to acquire additional resources held by other processes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No Preemption:&lt;/strong&gt; Resources can only be released voluntarily by the holding process after completion.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Circular Wait:&lt;/strong&gt; A closed chain of waiting processes exists, where each process waits for a resource held by the next process in the chain.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3&gt;V. CPU Scheduling Algorithms (Describe and Assess)&lt;span class="hx:absolute hx:-mt-20" id="v-cpu-scheduling-algorithms-describe-and-assess"&gt;&lt;/span&gt;
&lt;a href="#v-cpu-scheduling-algorithms-describe-and-assess" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;The CPU scheduler is the short-term scheduler that selects the next process residing in the ready queue to execute on the CPU. Scheduling decisions are either &lt;strong&gt;nonpreemptive&lt;/strong&gt; (when a process terminates or switches running &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo&gt;â†’&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;\to&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class="katex-html" aria-hidden="true"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.3669em;"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;â†’&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; waiting state) or &lt;strong&gt;preemptive&lt;/strong&gt; (when a process switches running &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo&gt;â†’&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;\to&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class="katex-html" aria-hidden="true"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.3669em;"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;â†’&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ready or waiting &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo&gt;â†’&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;\to&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class="katex-html" aria-hidden="true"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.3669em;"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;â†’&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; ready).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Scheduling Criteria (Assessment):&lt;/strong&gt; The goal is to maximize &lt;strong&gt;CPU utilization&lt;/strong&gt; and &lt;strong&gt;throughput&lt;/strong&gt;, while minimizing &lt;strong&gt;turnaround time&lt;/strong&gt;, &lt;strong&gt;waiting time&lt;/strong&gt;, and &lt;strong&gt;response time&lt;/strong&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left"&gt;Algorithm&lt;/th&gt;
&lt;th style="text-align: left"&gt;Description&lt;/th&gt;
&lt;th style="text-align: left"&gt;Assessment (Advantages/Disadvantages)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;First-Come, First-Served (FCFS)&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Processes are served in the order they arrive (FIFO queue). Nonpreemptive.&lt;/td&gt;
&lt;td style="text-align: left"&gt;Simple to implement. Can suffer from the &lt;strong&gt;convoy effect&lt;/strong&gt; (short processes stuck behind long ones), leading to high average waiting time.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Shortest-Job-First (SJF)&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Schedules the process with the shortest predicted next CPU burst time. Can be estimated using exponential averaging.&lt;/td&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Optimal&lt;/strong&gt;: gives the minimum average waiting time for a given set of processes. The main difficulty is predicting the length of the next CPU burst.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Shortest-Remaining-Time-First (SRTF)&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;The preemptive version of SJF.&lt;/td&gt;
&lt;td style="text-align: left"&gt;If a new process arrives with a shorter burst time than the currently running process&amp;rsquo;s remaining time, the current process is preempted.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Priority Scheduling (PR)&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;The CPU is allocated based on a priority number (smallest integer &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo&gt;â‰¡&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;\equiv&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class="katex-html" aria-hidden="true"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.4637em;"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;â‰¡&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; highest priority). Can be preemptive or nonpreemptive.&lt;/td&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Problem:&lt;/strong&gt; &lt;strong&gt;Starvation&lt;/strong&gt; (low-priority processes may never execute). &lt;strong&gt;Solution:&lt;/strong&gt; &lt;strong&gt;Aging&lt;/strong&gt; (gradually increasing the priority of processes waiting for a long time).&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Round Robin (RR)&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Each process receives a small &lt;strong&gt;time quantum&lt;/strong&gt; (&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;q&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class="katex-html" aria-hidden="true"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.625em;vertical-align:-0.1944em;"&gt;&lt;/span&gt;&lt;span class="mord mathnormal" style="margin-right:0.03588em;"&gt;q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;), typically 10â€“100 milliseconds. If the quantum expires, the process is preempted and added to the end of the ready queue.&lt;/td&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Good response time&lt;/strong&gt;. High overhead if &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;q&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class="katex-html" aria-hidden="true"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.625em;vertical-align:-0.1944em;"&gt;&lt;/span&gt;&lt;span class="mord mathnormal" style="margin-right:0.03588em;"&gt;q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is too small (relative to context switch time). If &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;q&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class="katex-html" aria-hidden="true"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.625em;vertical-align:-0.1944em;"&gt;&lt;/span&gt;&lt;span class="mord mathnormal" style="margin-right:0.03588em;"&gt;q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is large, it performs like FCFS.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Multilevel Feedback Queue&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Allows processes to move between different ready queues based on their CPU behavior (e.g., short interactive jobs stay in RR queues with small quanta; CPU-bound jobs drop to FCFS queues).&lt;/td&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Aging&lt;/strong&gt; can be easily implemented by moving processes between queues. Highly configurable based on criteria such as the number of queues and scheduling algorithms used for each queue.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h3&gt;VI. Real and Virtual Memory Management Schemes&lt;span class="hx:absolute hx:-mt-20" id="vi-real-and-virtual-memory-management-schemes"&gt;&lt;/span&gt;
&lt;a href="#vi-real-and-virtual-memory-management-schemes" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;A. Real (Physical) Memory Management&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The objective is to optimize CPU utilization and computer response by deciding what data moves into and out of memory, and allocating/deallocating memory space.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Memory Allocation Schemes (Describe and Assess):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Contiguous Allocation:&lt;/strong&gt; Each process is contained in a single contiguous section of memory.
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Assessment:&lt;/em&gt; Requires hardware support (Base/Limit registers) for protection. Suffers from &lt;strong&gt;external fragmentation&lt;/strong&gt; (total memory space exists, but is scattered/noncontiguous).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Segmentation:&lt;/strong&gt; A memory management scheme that supports the user&amp;rsquo;s view of memory, where a program is viewed as a collection of logical units (segments) such as the main program, procedures, stack, and heap.
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Assessment:&lt;/em&gt; Logical addresses are two-dimensional: &lt;code&gt;&amp;lt;segment-number, offset&amp;gt;&lt;/code&gt;. Still suffers from external fragmentation.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Paging:&lt;/strong&gt; The physical address space is noncontiguous, avoiding external fragmentation. Physical memory is divided into fixed-size blocks called &lt;strong&gt;frames&lt;/strong&gt;, and logical memory is divided into same-sized blocks called &lt;strong&gt;pages&lt;/strong&gt;.
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Assessment:&lt;/em&gt; Logical addresses are translated using a page table which maps page numbers (&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;p&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class="katex-html" aria-hidden="true"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.625em;vertical-align:-0.1944em;"&gt;&lt;/span&gt;&lt;span class="mord mathnormal"&gt;p&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;) to physical frame addresses. This scheme suffers from &lt;strong&gt;internal fragmentation&lt;/strong&gt; (allocated memory slightly larger than requested). Hardware support often includes a Translation Look-aside Buffer (TLB) to speed up address translation, as the page table is usually kept in main memory.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;B. Virtual Memory Management (Describe and Assess)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Virtual memory&lt;/strong&gt; separates user logical memory from physical memory, allowing the logical address space to be much larger than the physical address space. This allows more programs to run concurrently and requires less I/O for loading programs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Demand Paging:&lt;/strong&gt; The implementation method where a page is brought into memory only when it is actually needed (referenced).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Assessment:&lt;/em&gt; Reduces I/O and memory needed, leading to faster response. Requires hardware support, including a page table with a &lt;strong&gt;validâ€“invalid bit&lt;/strong&gt; (used to detect a &lt;strong&gt;page fault&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Effective Access Time (EAT):&lt;/strong&gt; Performance is sensitive to the &lt;strong&gt;page fault rate&lt;/strong&gt; (&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;p&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class="katex-html" aria-hidden="true"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.625em;vertical-align:-0.1944em;"&gt;&lt;/span&gt;&lt;span class="mord mathnormal"&gt;p&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;) because page fault service time (involving disk I/O) is extremely slow. &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;E&lt;/mi&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mi&gt;T&lt;/mi&gt;&lt;mo&gt;=&lt;/mo&gt;&lt;mo stretchy="false"&gt;(&lt;/mo&gt;&lt;mn&gt;1&lt;/mn&gt;&lt;mo&gt;âˆ’&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo stretchy="false"&gt;)&lt;/mo&gt;&lt;mo&gt;Ã—&lt;/mo&gt;&lt;mo stretchy="false"&gt;(&lt;/mo&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;y&lt;/mi&gt;&lt;mtext&gt;Â &lt;/mtext&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mtext&gt;Â &lt;/mtext&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo stretchy="false"&gt;)&lt;/mo&gt;&lt;mo&gt;+&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mo&gt;Ã—&lt;/mo&gt;&lt;mo stretchy="false"&gt;(&lt;/mo&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;g&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mtext&gt;Â &lt;/mtext&gt;&lt;mi&gt;f&lt;/mi&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mi&gt;u&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mtext&gt;Â &lt;/mtext&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;m&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mo stretchy="false"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;EAT = (1-p) \times (memory\ access\ time) + p \times (page\ fault\ time)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class="katex-html" aria-hidden="true"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.6833em;"&gt;&lt;/span&gt;&lt;span class="mord mathnormal" style="margin-right:0.05764em;"&gt;E&lt;/span&gt;&lt;span class="mord mathnormal"&gt;A&lt;/span&gt;&lt;span class="mord mathnormal" style="margin-right:0.13889em;"&gt;T&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.2778em;"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.2778em;"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:1em;vertical-align:-0.25em;"&gt;&lt;/span&gt;&lt;span class="mopen"&gt;(&lt;/span&gt;&lt;span class="mord"&gt;1&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.2222em;"&gt;&lt;/span&gt;&lt;span class="mbin"&gt;âˆ’&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.2222em;"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:1em;vertical-align:-0.25em;"&gt;&lt;/span&gt;&lt;span class="mord mathnormal"&gt;p&lt;/span&gt;&lt;span class="mclose"&gt;)&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.2222em;"&gt;&lt;/span&gt;&lt;span class="mbin"&gt;Ã—&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.2222em;"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:1em;vertical-align:-0.25em;"&gt;&lt;/span&gt;&lt;span class="mopen"&gt;(&lt;/span&gt;&lt;span class="mord mathnormal"&gt;m&lt;/span&gt;&lt;span class="mord mathnormal"&gt;e&lt;/span&gt;&lt;span class="mord mathnormal"&gt;m&lt;/span&gt;&lt;span class="mord mathnormal" style="margin-right:0.03588em;"&gt;ory&lt;/span&gt;&lt;span class="mspace"&gt;Â &lt;/span&gt;&lt;span class="mord mathnormal"&gt;a&lt;/span&gt;&lt;span class="mord mathnormal"&gt;ccess&lt;/span&gt;&lt;span class="mspace"&gt;Â &lt;/span&gt;&lt;span class="mord mathnormal"&gt;t&lt;/span&gt;&lt;span class="mord mathnormal"&gt;im&lt;/span&gt;&lt;span class="mord mathnormal"&gt;e&lt;/span&gt;&lt;span class="mclose"&gt;)&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.2222em;"&gt;&lt;/span&gt;&lt;span class="mbin"&gt;+&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.2222em;"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.7778em;vertical-align:-0.1944em;"&gt;&lt;/span&gt;&lt;span class="mord mathnormal"&gt;p&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.2222em;"&gt;&lt;/span&gt;&lt;span class="mbin"&gt;Ã—&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.2222em;"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:1em;vertical-align:-0.25em;"&gt;&lt;/span&gt;&lt;span class="mopen"&gt;(&lt;/span&gt;&lt;span class="mord mathnormal"&gt;p&lt;/span&gt;&lt;span class="mord mathnormal"&gt;a&lt;/span&gt;&lt;span class="mord mathnormal" style="margin-right:0.03588em;"&gt;g&lt;/span&gt;&lt;span class="mord mathnormal"&gt;e&lt;/span&gt;&lt;span class="mspace"&gt;Â &lt;/span&gt;&lt;span class="mord mathnormal" style="margin-right:0.10764em;"&gt;f&lt;/span&gt;&lt;span class="mord mathnormal"&gt;a&lt;/span&gt;&lt;span class="mord mathnormal"&gt;u&lt;/span&gt;&lt;span class="mord mathnormal"&gt;lt&lt;/span&gt;&lt;span class="mspace"&gt;Â &lt;/span&gt;&lt;span class="mord mathnormal"&gt;t&lt;/span&gt;&lt;span class="mord mathnormal"&gt;im&lt;/span&gt;&lt;span class="mord mathnormal"&gt;e&lt;/span&gt;&lt;span class="mclose"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. To maintain reasonable performance, &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;p&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class="katex-html" aria-hidden="true"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.625em;vertical-align:-0.1944em;"&gt;&lt;/span&gt;&lt;span class="mord mathnormal"&gt;p&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; must be very small.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Page Replacement (Describe and Assess):&lt;/strong&gt; Required when a page fault occurs and no free frames are available. A &lt;strong&gt;modify (dirty) bit&lt;/strong&gt; reduces overhead by indicating whether a victim page needs to be written back to disk.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style="text-align: left"&gt;Algorithm&lt;/th&gt;
&lt;th style="text-align: left"&gt;Description&lt;/th&gt;
&lt;th style="text-align: left"&gt;Assessment (Pros/Cons)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;First-In-First-Out (FIFO)&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Replaces the page that has been in memory the longest (oldest).&lt;/td&gt;
&lt;td style="text-align: left"&gt;Simple. Suffers from &lt;strong&gt;Beladyâ€™s Anomaly&lt;/strong&gt;, where increasing the number of allocated frames can sometimes increase the page fault rate.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Optimal (OPT)&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Replaces the page that will not be used for the longest period of time in the future.&lt;/td&gt;
&lt;td style="text-align: left"&gt;Impossible to implement since it requires predicting the future. Used solely as a standard for comparison.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;Least Recently Used (LRU)&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Replaces the page that has not been used for the longest time in the past.&lt;/td&gt;
&lt;td style="text-align: left"&gt;Generally a good algorithm that does not suffer from Belady&amp;rsquo;s Anomaly. Implementation requires expensive hardware support (counters or stacks) to track usage time.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="text-align: left"&gt;&lt;strong&gt;LRU Approximation (e.g., Second-Chance)&lt;/strong&gt;&lt;/td&gt;
&lt;td style="text-align: left"&gt;Uses a reference bit; pages are replaced if the reference bit is 0. If 1, the bit is cleared and the process checks the next oldest page.&lt;/td&gt;
&lt;td style="text-align: left"&gt;An efficient attempt to approximate LRU behavior without complex hardware.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Thrashing:&lt;/strong&gt; A state where a process is busy swapping pages in and out because it does not have enough frames allocated to hold its current working set (locality). This results in low CPU utilization. Limiting the effects of thrashing requires using local or priority page replacement policies.&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;VII. Assignment-Specific and Course Relevant Topics&lt;span class="hx:absolute hx:-mt-20" id="vii-assignment-specific-and-course-relevant-topics"&gt;&lt;/span&gt;
&lt;a href="#vii-assignment-specific-and-course-relevant-topics" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Assignment 1 Specifics: Shared Memory and Multi-Tasking&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Assignment 1 involves writing producer and consumer programs that communicate via a &lt;strong&gt;bounded buffer in shared memory&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The Producer (parent) uses &lt;code&gt;fork()&lt;/code&gt; to create the Consumer (child) and loads the consumer executable using &lt;code&gt;exec()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;A fixed-size shared memory block (4K) is created by the producer using &lt;code&gt;InitShm()&lt;/code&gt;. This block contains a header with: &lt;code&gt;bufSize&lt;/code&gt; (buffer capacity), &lt;code&gt;itemCnt&lt;/code&gt; (items to produce/consume), &lt;code&gt;in&lt;/code&gt; (index of next item to produce), and &lt;code&gt;out&lt;/code&gt; (index of next item to consume).&lt;/li&gt;
&lt;li&gt;The producer must &lt;strong&gt;wait&lt;/strong&gt; if the bounded buffer is full. The consumer must &lt;strong&gt;wait&lt;/strong&gt; if the bounded buffer is empty.&lt;/li&gt;
&lt;li&gt;Synchronization must be maintained by using specified functions to read/write the shared &lt;code&gt;in&lt;/code&gt; and &lt;code&gt;out&lt;/code&gt; variables (&lt;code&gt;GetIn/Out()&lt;/code&gt;, &lt;code&gt;SetIn/Out()&lt;/code&gt;) and to access the buffer contents (&lt;code&gt;ReadAtBufIndex()&lt;/code&gt;, &lt;code&gt;WriteAtBufIndex()&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Assignment 2 Specifics: CPU Scheduling Algorithms&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Assignment 2 focuses on simulating four CPU scheduling algorithms, assuming a single CPU:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Round Robin (RR):&lt;/strong&gt; Processes are added to a FIFO queue based on arrival time. The time quantum is a parameter. If the quantum expires, the process goes to the end of the queue.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Shortest Job First (SJF) (Non-preemptive):&lt;/strong&gt; Scheduling decisions occur only when the current process terminates. The next process chosen is the one that has arrived and has the shortest CPU burst length. Ties are broken by arrival time (FCFS).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Priority Scheduling without Preemption (PR noPREMP):&lt;/strong&gt; Scheduling decisions occur only upon termination. The process with the highest priority (smallest number) is chosen. Ties are broken arbitrarily.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Priority Scheduling with Preemption (PR withPREMP):&lt;/strong&gt; Scheduling decisions occur upon termination OR when a higher priority process arrives. If a higher priority process arrives, the current CPU-holding process is preempted and added back to the priority queue.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;OS Design and Implementation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A crucial design principle is separating &lt;strong&gt;Policy&lt;/strong&gt; (what will be done?) from &lt;strong&gt;Mechanism&lt;/strong&gt; (how to do it?). Mechanisms determine &lt;em&gt;how&lt;/em&gt; to accomplish a task, while policies decide &lt;em&gt;what&lt;/em&gt; needs to be done. Separating them allows policy changes without changing underlying mechanisms.&lt;/p&gt;
&lt;p&gt;OS structures vary widely:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Simple Structure (MS-DOS):&lt;/strong&gt; Not divided into modules, interfaces and functionality poorly separated.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Traditional UNIX:&lt;/strong&gt; Limited structuring, consists of systems programs and the kernel (everything below the system-call interface).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Microkernel:&lt;/strong&gt; Moves as much functionality as possible from the kernel into user space, communicating via message passing. Benefits include being easier to extend/port, more reliable, and more secure; the detriment is performance overhead due to communication.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hybrid Systems:&lt;/strong&gt; Most modern OSs combine multiple approaches (e.g., Linux/Solaris are monolithic plus modular; Mac OS X uses a Mach microkernel base combined with BSD UNIX parts).&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;Summary of Questions from Source Materials&lt;span class="hx:absolute hx:-mt-20" id="summary-of-questions-from-source-materials"&gt;&lt;/span&gt;
&lt;a href="#summary-of-questions-from-source-materials" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;The following is a condensed list of all multiple-choice and essay questions found in the provided slides, categorized by relevant topic:&lt;/p&gt;
&lt;h3&gt;Functions of an Operating System &amp;amp; OS Structure&lt;span class="hx:absolute hx:-mt-20" id="functions-of-an-operating-system--os-structure"&gt;&lt;/span&gt;
&lt;a href="#functions-of-an-operating-system--os-structure" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;This topic covers the definition and goals of an OS, its components, and system architecture.
Questions include: How an operating system is like a government (it creates an environment for other programs to do work); what program runs all the time on the computer (the kernel); describing the four components of computer systems; describing OS design goals (convenience, reliability, safety, speed, ease of design/maintenance); and determining which statement relating to OS services, resource management, interfaces, protection, and security is incorrect. It also asks how microkernels handle communication (message passing), and defines the relationship between an API, the system-call interface, and the operating system.&lt;/p&gt;
&lt;h3&gt;Interrupts, Bootstrapping, and System Calls&lt;span class="hx:absolute hx:-mt-20" id="interrupts-bootstrapping-and-system-calls"&gt;&lt;/span&gt;
&lt;a href="#interrupts-bootstrapping-and-system-calls" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;This covers how the OS starts and how user programs request services.
Questions address: Which stage triggers the CPU switch from user program to interrupt processing; what a bootstrap program is and where it is stored (ROM/EPROM/firmware); the three general methods used to pass parameters during system calls (registers, block/table in memory, or pushed onto the stack); which mechanism provides the interface to OS services (system calls); and why clustered systems provide high-availability service.&lt;/p&gt;
&lt;h3&gt;Process and Thread Management&lt;span class="hx:absolute hx:-mt-20" id="process-and-thread-management"&gt;&lt;/span&gt;
&lt;a href="#process-and-thread-management" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;This section addresses the definition, states, creation, and advantages of processes and threads.
Questions cover: What area contains dynamically allocated data during runtime (heap section); which process state is switched to from &amp;lsquo;running&amp;rsquo; when an I/O event occurs (waiting); scenarios that force a process off the CPU (I/O request, fork, interrupt/time slice expired); defining and describing the different process states; explaining why Google Chrome uses multiple processes; discussing the consequences of calling &lt;code&gt;exec()&lt;/code&gt; before &lt;code&gt;fork()&lt;/code&gt;; identifying items shared across threads of the same process (code, data, files); explaining why a web server shouldn&amp;rsquo;t be single-threaded; listing and explaining the four major benefits of multithreaded programming (Responsiveness, Resource Sharing, Economy, Scalability); and defining and justifying the use of a thread pool.&lt;/p&gt;
&lt;h3&gt;CPU Scheduling&lt;span class="hx:absolute hx:-mt-20" id="cpu-scheduling"&gt;&lt;/span&gt;
&lt;a href="#cpu-scheduling" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;This includes scheduling algorithms, criteria, and related concepts like latency.
Questions focus on: Which criterion is most important for an interactive system (response time); which circumstance cooperative scheduling can take place (running to waiting state switch); which algorithm must be nonpreemptive (FCFS); defining the role of the dispatcher; explaining starvation and how aging prevents it; identifying the two types of latency affecting real-time systems (interrupt latency, dispatch latency); and which term describes the capability for multiple tasks to make progress on a single processor system (concurrency).&lt;/p&gt;
&lt;h3&gt;Concurrency and Synchronization&lt;span class="hx:absolute hx:-mt-20" id="concurrency-and-synchronization"&gt;&lt;/span&gt;
&lt;a href="#concurrency-and-synchronization" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;This section includes race conditions, critical section solutions, and classic synchronization problems.
Questions require: Explaining race conditions (concurrent access leading to outcome dependent on access order); assessing the relationship between the three critical section requirements (Mutual Exclusion, Progress, Bounded Waiting); discussing whether counting semaphores can be used to control access to resources with a finite number of instances (Yes); contrasting semaphores and mutex locks; detailing approaches to handle critical sections in OSs; analyzing structural changes in the bounded buffer producer process and the resulting blocking; describing scenarios for when using a readerâ€“writer lock is preferable to a semaphore; explaining the difference between the first and second readers-writers problems; and describing a starvation scenario in the monitor solution for the dining philosophers problem.&lt;/p&gt;
&lt;h3&gt;Deadlocks&lt;span class="hx:absolute hx:-mt-20" id="deadlocks"&gt;&lt;/span&gt;
&lt;a href="#deadlocks" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;This covers the characterization and handling of deadlocks.
Questions address: The necessary condition for deadlock stating a resource must be nonsharable (mutual exclusion); whether an unsafe state necessarily leads to a deadlocked state (it may lead to it); explaining the four necessary conditions for deadlock (Mutual Exclusion, Hold and Wait, No Preemption, Circular Wait); listing the three general ways deadlocks are handled (prevention, avoidance, recovery/ignoring); and describing protocols to prevent the hold-and-wait condition.&lt;/p&gt;
&lt;h3&gt;Memory Management (Real and Virtual)&lt;span class="hx:absolute hx:-mt-20" id="memory-management-real-and-virtual"&gt;&lt;/span&gt;
&lt;a href="#memory-management-real-and-virtual" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;This topic covers address binding, allocation methods, fragmentation, paging, and demand paging.
Questions include: Identifying the binding method used by most general-purpose OSs (execution time binding); calculating the page number from a given logical address and page size (requires calculation); distinguishing between internal and external fragmentation; describing how a TLB assists address translation; calculating context switch time associated with swapping (requires calculation based on transfer rate/latency); explaining the distinction between demand paging and paging with swapping; explaining how Effective Access Time is computed for demand paging; explaining why a local replacement algorithm doesn&amp;rsquo;t entirely solve thrashing; identifying when a page is loaded in demand paging (only when needed during execution); and identifying what the dirty (modify) bit signals (the page has been modified since loading).&lt;/p&gt;
&lt;h3&gt;Storage and File System Implementation (General Course Relevance)&lt;span class="hx:absolute hx:-mt-20" id="storage-and-file-system-implementation-general-course-relevance"&gt;&lt;/span&gt;
&lt;a href="#storage-and-file-system-implementation-general-course-relevance" class="subheading-anchor" aria-label="Permalink for this section"&gt;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Questions address: The two components of positioning time (seek time + rotational latency); which disk scheduling algorithm ignores the current head position (FCFS); describing a disadvantage of FCFS disk scheduling (long waits); listing the factors influencing disk-scheduling algorithm selection; which structure reads and writes physical blocks (basic file system); what structures implement a file system (boot control block, volume control block, directory structure); and explaining why the entire block is unavailable to a user when linked allocation is employed.&lt;/p&gt;</description></item></channel></rss>